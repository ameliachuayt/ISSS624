---
title: "Global and Local Measures of Spatial Autocorrelation"
author: "Amelia Chua"
editor: visual
number-sections: true
---

## Overview

In this hands-on exercise, I learned how to compute Global and Local Measure of Spatial Autocorrelation (GLSA) by using **spdep** package. By the end to this hands-on exercise, I was able to:

-   import geospatial data using appropriate function(s) of **sf** package,

-   import csv file using appropriate function of **readr** package,

-   perform relational join using appropriate join function of **dplyr** package,

-   compute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of **spdep** package,

    -   plot Moran scatterplot,

    -   compute and plot spatial correlogram using appropriate function of **spdep** package.

-   compute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions **spdep** package;

-   compute Getis-Ord's Gi-statistics for detecting hot spot or/and cold spot area by using appropriate functions of **spdep** package; and

-   to visualise the analysis output by using **tmap** package.

## Getting Started

### The analytical question

In spatial policy, one of the main development objectives of the local govenment and planners is to **ensure equal distribution of development** in the province. Our task in this study, hence, is to **apply appropriate spatial statistical methods to discover if development are even distributed geographically**.

If the answer is **No**. Then, our next question would be "is there sign of spatial clustering?". And, if the answer for this question is **Yes**, then our next question will be "where are these clusters?"

In this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita or GDPPC) of [Hunan Province](https://en.wikipedia.org/wiki/Hunan), People Republic of China.

### The Study Area and Data

Two data sets will be used in this hands-on exercise, they are:

-   Hunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.

-   Hunan_2012.csv: This csv file contains selected Hunan's local development indicators in 2012.

### Setting the Analytical Tools

The code chunk below installs and loads **sf**, **spdep**, **tmap** and **tidyverse** packages into R environment. [*pacman()*](https://cran.r-project.org/web/packages/pacman/readme/README.html) is a R package management tool. It provides intuitively named functions for the base functions.

```{r}
pacman::p_load(sf, spdep, tmap, tidyverse)
```

## Importing Data into R Environment

The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.

### Import shapefile into R

The code chunk below uses [*st_read()*](https://r-spatial.github.io/sf/reference/st_read.html) of **sf** package to import Hunan shapefile into R. The imported shapefile will be **simple features** object of **sf**.

```{r}
hunan <- st_read(dsn = 'data\\geospatial',
                 layer = 'Hunan')
```

From the output, we can see that there are 88 multipolygons and 7 fields.

### Import csv file into R

```{r}
hunan2012 <- read_csv("data\\aspatial\\Hunan_2012.csv", show_col_types = FALSE)
```

### Performing relational join

The code chunk below will be used to update the attribute table of *hunan*'s SpatialPolygonsDataFrame with the attribute fields of *hunan2012* dataframe. This is performed by using *left_join()* of **dplyr** package.

```{r}
hunan <- left_join(hunan, hunan2012)
```

### Visualising Regional Development Indicator

The code chunk below is used to prepare two stand-alone choropleth maps to visualise the distribution of GDPPC 2012 by using *gtm()* of **tmap** package. The map on the left will be classified using equal intervals and the one on the right will be classified using quantiles.

Then by using *tmap_arrange()* of **tmap** package, we will create a facet map.

Note that:

-   GDPPC refers to Gross Domestic Product per capita.

-   *qtm()* allows us to plot thematic maps quickly.

```{r}

equal <- tm_shape(hunan) +
  tm_fill("GDPPC", 
          n = 5, 
          style = 'equal') + 
  tm_borders(alpha = 0.5) + 
  tm_layout(main.title = 'Equal Interval Classification')

quantile <- tm_shape(hunan) + 
  tm_fill("GDPPC", 
          n = 5, 
          style = 'quantile') + 
  tm_borders(alpha = 0.5) + 
  tm_layout(main.title = "Equal Quantile Classification")

tmap_arrange(equal, quantile, asp = 1, ncol = 2)
```

## Global Spatial Autocorrelation

In this section, I learned how to compute global spatial autocorrelation statistics and how to perform spatial complete randomness test for global spatial autocorrelation.

### Computing Contiguity Spatial Weights

Before we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.

In the code chunk below, [*poly2nb()*](https://r-spatial.github.io/spdep/reference/poly2nb.html) of **spdep** package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. By default, Queen contiguity is applied.

```{r}
wm_q <- poly2nb(hunan, 
                queen = TRUE)
summary(wm_q)
```

The summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two least connected area with only one neighbour.

### Row-standardised weights matrix

Next, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=\"W\"). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighbouring county then summing the weighted income values.

While this is the most intuitive way to summaries the neighbors\' values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data.

Note that other more robust options are available, notably style=\"B\".

```{r}
rswm_q <- nb2listw(wm_q,
                   style = "W",
                   zero.policy = TRUE)
rswm_q
```

### Global Spatial Autocorrelation: Moran's I

In this section, I learned how to perform Moran's I statistical testing by using [*moran.test()*](https://r-spatial.github.io/spdep/reference/moran.test.html) of **spdep**.

    moran.test(x, listw, randomisation=TRUE, zero.policy=NULL,
     alternative="greater", rank = FALSE, na.action=na.fail, spChk=NULL,
     adjust.n=TRUE, drop.EI2=FALSE)

Moran's I describe how features differ from the values in the study area as a whole. If the Moran I (Z-value is):

-   positive (I\>0): Clustered, observations tend to be similar

-   negative (I\<0): Disperse, observations tend to be dissimilar

-   approximately zero: observations arranged randomly over space

We will test the following hypothesis:

-   H0: Observed spatial patterns of values is equally likely as any other spatial pattern i.e. data is randomly disbursed, no spatial pattern

-   H1: Data is more spatially clustered than expected by chance alone.

```{r}
moran.test(hunan$GDPPC,
           listw = rswm_q,
           zero.policy = TRUE,
           na.action = na.omit)
```

Since the p-value \< 0.05, we have sufficient statistical evidence to reject the null hypothesis at the 95% level of confidence. This means that data is more spatially clustered than expected by chance alone. Since Moran I statistic \> 0.300, the observation are clustered, observations tend to be similar.

#### Computing Monte Carlo Moran's I

If we have doubts that the assumptions of Moran's I are true (normality and randomisation), we can use a Monte Carlo simulation to perform a permutation test for Moran's I.

The permutation tests consists of randomly reassigning the attribute values to a cell under the assumption of no spatial pattern. This random assignment is conducted n times. Each time, we will compute the Moran's I to creating an empirical distribution of Moran's I under H0.

The code chunk below performs permutation test for Moran\'s I statistic by using [*moran.mc()*](https://r-spatial.github.io/spdep/reference/moran.mc.html) of **spdep**. A total of 1000 simulation will be performed.

    moran.mc(x, listw, nsim, zero.policy=NULL, alternative="greater",
     na.action=na.fail, spChk=NULL, return_boot=FALSE, adjust.n=TRUE)

We will test the following hypothesis using a one-tailed test:

-   H0: Observed spatial patterns of values is equally likely as any other spatial pattern i.e. data is randomly disbursed, no spatial pattern

-   H1: Data is more spatially clustered than expected by chance alone.

```{r}
set.seed(1234)
bperm = moran.mc(hunan$GDPPC, 
         listw = rswm_q,
         nsim = 999,
         zero.policy = TRUE,
         na.action = na.omit)
bperm
```

Since the **pseudo** p-value \< 0.05, we have sufficient statistical evidence to reject the null hypothesis at the 95% level of confidence. This means that data is more spatially clustered than expected by chance alone.

#### Visualising Monte Carlo Moran's I

We can examine the simulated Moran\'s I test statistics in greater detail through descriptive statistics and plotting the distribution of the statistical values as a histogram by using the code chunks below.

The mean gives the average of Moran's I for all simulated distributions.

```{r}
mean(bperm$res[1:999])
```

The variance of Moran\'s I for all simulated distributions can be computed using this code chunk.

```{r}
var(bperm$res[1:999])
```

```{r}
summary(bperm$res[1:999])
```

```{r}
hist(bperm$res,
     freq = TRUE,
     breaks = 20,
     xlab = "Simulated Moran's I")
abline(v=0, 
       col = 'red')
abline(v=0.30075, #actual moran's I
       col = 'blue')
```

From the output above, we can see that the distribution of the simulated values of Moran's I is slightly skewed to the right. The blue line above indicates the actual value of Moran's I, which is near the extremes of the distribution. This suggests that there is evidence of positive autocorrelation i.e. cluster. ([Reference](https://gis.stackexchange.com/questions/161887/significance-test-for-morans-i-using-monte-carlo-simulation))

We can also plot the above graph using **ggplot2** package. To do so, we must first convert the results into a dataframe.

```{r}
df <- as.data.frame(bperm$res)
colnames(df) <- c("Simulated Moran's I")
```

```{r}
ggplot(df, aes(x=`Simulated Moran's I`)) + 
  geom_histogram(color = "darkblue", fill = "lightblue", bins = 20) +
  ylab('Frequency')
```

### Global Spatial Autocorrelation: Geary's C

In this section, I learned how to perform Geary\'s C statistics testing by using appropriate functions of **spdep** package.

#### Geary's C Test

Geary's C describe how features differ from their immediate neighbours. If the Geary's C (Z-value is):

-   Large (c\>1): Dispersed, observations tend to be dissimilar

-   Small (c\<1): Clustered, observations tend to be similar

-   c = 1: observations arranged randomly over space

We will test the following hypothesis:

-   H0: Observed spatial patterns of values is equally likely as any other spatial pattern i.e. data is randomly disbursed, no spatial pattern

-   H1: Data is more spatially clustered than expected by chance alone

The code chunk below performs Geary\'s C test for spatial autocorrelation by using [*geary.test()*](https://r-spatial.github.io/spdep/reference/geary.test.html) of **spdep**.

    geary.test(x, listw, randomisation=TRUE, zero.policy=NULL,
        alternative="greater", spChk=NULL, adjust.n=TRUE)

```{r}
geary.test(hunan$GDPPC, listw = rswm_q)
```

Since the p-value = 0.0001526 \< 0.05, we have sufficient statistical evidence to reject the null hypothesis at the 95% level of confidence. This means that data is more spatially clustered than expected by chance alone.

#### Computing Monte Carlo Geary's C

The code chunk below performs permutation test for Geary\'s C statistic by using [*geary.mc()*](https://r-spatial.github.io/spdep/reference/geary.mc.html) of **spdep**.

```{r}
set.seed(1234)
bperm = geary.mc(hunan$GDPPC,
                 listw = rswm_q,
                 nsim = 999)
bperm
```

Since the **pseudo** p-value = 0.001 \< 0.05, we have sufficient statistical evidence to reject the null hypothesis at the 95% level of confidence. This means that data is more spatially clustered than expected by chance alone.

#### Visualising the Monte Carlo Geary's C

We can examine the simulated Geary's C test statistics in greater detail through descriptive statistics and plotting the distribution of the statistical values as a histogram by using the code chunks below.

The mean gives the average of Geary's C for all simulated distributions.

```{r}
mean(bperm$res[1:999])
```

The variance of Geary's C for all simulated distributions can be computed using this code chunk.

```{r}
var(bperm$res[1:999])
```

```{r}
summary(bperm$res[1:999])
```

```{r}
hist(bperm$res,
     freq = TRUE,
     breaks = 20,
     xlab = "Simulated Geary's C")
abline(v=1, 
       col = 'red')

```

From the output above, we can see that the distribution of the simulated values of Moran's I fairly normally distributed.

## Spatial Correlogram

Spatial correlograms are great to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran\'s I or Geary\'s c) against distance.Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.

### Compute Moran's I correlogram

In the code chunk below, [*sp.correlogram()*](https://r-spatial.github.io/spdep/reference/sp.correlogram.html) of **spdep** package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran\'s I. The **plot()** of base Graph is then used to plot the output.

    sp.correlogram(neighbours, var, order = 1, method = "corr",
     style = "W", randomisation = TRUE, zero.policy = NULL, spChk=NULL)
    # S3 method for spcor
    plot(x, main, ylab, ylim, ...)
    # S3 method for spcor
    print(x, p.adj.method="none", ...)

```{r}
MI_corr <- sp.correlogram(wm_q, #note that we used the original weights matrix
                          hunan$GDPPC,
                          order = 6,
                          method = 'I',
                          style = 'W')
plot(MI_corr)
```

Next, let's examine the full analysis report and view which values are statistically significant.

```{r}
print(MI_corr)
```

From the output, we see that with the exception of Lag 4, the rest of the results are statistically significant at the 95% level of confidence.

### Compute Geary's C correlogram and plot

In the code chunk below, *sp.correlogram()* of **spdep** package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary\'s C. The **plot()** of base Graph is then used to plot the output.

```{r}
GC_corr <- sp.correlogram(wm_q,
                          hunan$GDPPC,
                          order = 6, 
                          method = "C",
                          style = "W")
plot(GC_corr)
```

Next, let's examine the full analysis report and view which values are statistically significant.

```{r}
print(GC_corr)
```

From the output, we see that with the exception of Lag 3, 4 and 6, the rest of the results are statistically significant at the 95% level of confidence.

## Cluster and Outlier Analysis

Local Indicators of Spatial Association or LISA are statistics that **evaluate the existence of clusters in the spatial arrangement of a given variable**. For instance if we are studying cancer rates among census tracts in a given city, local clusters in the rates mean that there are areas that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.

In this section, I learned how to apply appropriate Local Indicators for Spatial Association (LISA), especially local Moran\'s I to detect cluster and/or outlier from GDP per capita 2012 of Hunan Province, PRC.

### Computing local Moran's I

To compute local Moran\'s I, the [*localmoran()*](https://r-spatial.github.io/spdep/reference/localmoran.html) function of **spdep** will be used. It computes *Ii* values, given a set of *zi* values and a listw object providing neighbour weighting information for the polygon associated with the zi values.

The code chunks below are used to compute local Moran\'s I of *GDPPC2012* at the county level.

```{r}
localMI <- localmoran(hunan$GDPPC, rswm_q)
head(localMI)
```

*localmoran()* returns a matrix of values whose columns are:

-   Ii: the local Moran\'s I statistics

-   E.Ii: the expectation of local moran statistic under the randomisation hypothesis

-   Var.Ii: the variance of local moran statistic under the randomisation hypothesis

-   Z.Ii:the standard deviation of local moran statistic

-   Pr(): the p-value of local moran statistic

The code chunk below list the content of the local Moran matrix derived by using [*printCoefmat()*](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/printCoefmat).

```{r}
fips <- order(hunan$County) #order in alphabetical order, returns index of the variable
printCoefmat(data.frame(localMI[fips,],
                        row.names=hunan$County[fips]), check.names=FALSE)
```

#### Mapping the local Moran's I

Before mapping the local Moran\'s I map, I would append the local Moran\'s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame. The code chunks below can be used to perform the task.

```{r}
hunan.localMI <- cbind(hunan, localMI) %>%
rename(Pr.Ii = Pr.z....E.Ii..)
```

#### Mapping local Moran's I values

Using choropleth mapping functions of **tmap** package, we can plot the local Moran\'s I values by using the code chinks below.

```{r}
localMI.map <- tm_shape(hunan.localMI) + 
                  tm_fill(col = "Ii",
                          style = 'pretty',
                          title = "Local Moran Statistics") + 
                  tm_borders(alpha = 0.5)
localMI.map
```

#### Mapping local Moran's I p-values

The choropleth above shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.

The code chunks below produce a choropleth map of Moran\'s I p-values by using functions of **tmap** package.

```{r}
pvalue.map <- tm_shape(hunan.localMI) + 
                tm_fill(col = "Pr.Ii",
                       breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
                       palette = "-Blues",
                       title = "Local Moran's I p-values") + 
                tm_borders(alpha = 0.5)

pvalue.map
```

We can see that only the darker blue areas are within the 0.05 significance level. This means that not all the local Moran's I values are statistically significant at the 95% confidence level.

#### Mapping both local Moran's I values and 

We can plot both the local Moran\'s I values map and its corresponding p-values map next to each other using *tmap_arrange()* from **tmap** package.

```{r}
tmap_arrange(localMI.map, pvalue.map, asp = 1, ncol = 2)
```

## Creating a LISA Cluster Map

The LISA Cluster Map shows the significant locations colour coded by type of spatial autocorrelation. Before we generate the LISA Cluster Map, we must plot the Moran scatterplot.

### Plotting Moran scatterplot

The Moran scatterplot illustrates the relationship between the values of the chosen attribute e.g., GDPPC at each location and the average value of the same attribute at neighbouring locations.

We can plot the Moran scatterplot of GDPPC 2012 by using [*moran.plot()*](https://r-spatial.github.io/spdep/reference/moran.plot.html) of **spdep**.

```{r}
nci <- moran.plot(hunan$GDPPC, rswm_q,
                  labels = as.character(hunan$County),
                  xlab = "GDPPC 2012",
                  ylab = "Spatially Lag GDPPC 2012")
```

The Moran scatterplot is split into 4 quadrants:

-   **Top right corner (High-High**): Autocorrelation Positive Cluster that belongs to counties with **high** GDPPC and are surrounded by other areas that have the **higher than** average level of GDPPC.

-   Top left corner (Low-High): Autocorrelation Negative Cluster that belongs to counties with **low** GDPPC among **high** GDPPC neighboours

-   Bottom right corner (High-Low): Autocorrelation Negative Cluster that belongs to counties with **high** GDPPC among **low** GDPPC neighbours.

-   Bottom left corner (Low-Low): Autocorrelation Positive Cluster that belongs to counties with have **low** GDPPC among **low** GDPPC neighbours.

### Plotting Moran scatterplot with standardised variable

We can use [*scale()*](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/scale) to center and scale the variable. Centering is done by subtracting the mean (omitting NAs) from the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.

The above describes the Z-standardisation.

The below code chunk will create a new column `Z.GDPPC` in the `hunan` dataframe to store the standardised GDPPC values. The [*as.vector()*](https://www.rdocumentation.org/packages/pbdDMAT/versions/0.5-1/topics/as.vector) added to the end is to make sure that the data type we get out of this is a vector, that map neatly into out dataframe.

```{r}
hunan$Z.GDPPC <- scale(hunan$GDPPC) %>%
  as.vector
head(hunan,3)
```

In the output above, we can see the new column added.

We can now plot the Moran scatterplot using the `Z.GDPPC`, the standardised GDPPC values.

```{r}
nci2 <- moran.plot(hunan$Z.GDPPC, rswm_q,
                   labels = as.character(hunan$County),
                   xlab = "Z-GDPPC 2012",
                   ylab = "Spatially Lag z-GDPPC 2012")
```

In the output above, we notice that the x-axis ranged has been scaled down as compared to the previous section.

### Preparing LISA map classes

We can prepare a LISA cluster map by following the steps:

```{r}
#create a vector 
quadrant <- vector(mode = "numeric", length = nrow(localMI))
```

Center attribute (GDPPC) around its mean.

```{r}
DV <- hunan$GDPPC - mean(hunan$GDPPC)
```

Next, centering the local Moran's I around its mean.

```{r}
C_MI <- localMI[,1] - mean(localMI[,1])
```

Set statistical significance level for the local Moran.

```{r}
signif <- 0.05
```

Define the command lines for: high-high, low-low, low-high, high-low categories.

```{r}
quadrant[DV > 0 & C_MI > 0] <- 4 #high-high
quadrant[DV < 0 & C_MI < 0] <- 1 #low-low
quadrant[DV < 0 & C_MI > 0] <- 2 #low-high
quadrant[DV > 0 & C_MI < 0] <- 3 #high-low
```

Lastly, place non-significant Moran in the category 0.

```{r}
quadrant[localMI[,5]>signif] <- 0
```

Alternatively, we can combine all the above steps into a single code chunk.

```{r}
quadrant <- vector(mode="numeric",length=nrow(localMI))
DV <- hunan$GDPPC - mean(hunan$GDPPC)     
C_mI <- localMI[,1] - mean(localMI[,1])    
signif <- 0.05       
quadrant[DV > 0 & C_MI > 0] <- 4 #high-high
quadrant[DV < 0 & C_MI < 0] <- 1 #low-low
quadrant[DV < 0 & C_MI > 0] <- 2 #low-high
quadrant[DV > 0 & C_MI < 0] <- 3 #high-low
quadrant[localMI[,5]>signif] <- 0
```

### Plotting LISA Map

Let's build the LISA map using the following code chunk.

```{r}
#Assign each county to its respective quardrant
hunan.localMI$quadrant <- quadrant
#Set the colours--one for each quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c") 
#Name the clusters 0 > 1 > 2 > 3 > 4
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAmap <- tm_shape(hunan.localMI) + 
  tm_fill(col = "quadrant",
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1],
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) + 
  tm_borders(alpha = 0.5)

LISAmap          
```

We can plot both the local Moran's I map and LISA Map together

```{r}
tmap_arrange(localMI.map, LISAmap, asp = 1, ncol = 2 )
```

We can also visualise the GDPPC and LISAmap together

```{r}
gdppc <- qtm(hunan, fill = "GDPPC")
tmap_arrange(gdppc, LISAmap, asp = 1, ncol = 2)
```

From the outputs above, we can see that there are three areas of outliers---counties shaded in light blue and light orange. The light blue regions are outliers, where they have lower GDPPC as compared to their neighbours, and vice versa for the region in orange. On the other hand, the regions that are dark blue and red are considered clusters.

## Hot Spot and Cold Spot Area Analysis

Beside detecting clusters and outliers, localised spatial statistics can also be used to detect hot spot and/or cold spot areas. Hot spot refers to areas that have higher values relative to its surroundings.

### Getis and Ord's G-Statistics

The Getis and Ord\'s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995) are alternative spatial statistics to detect spatial anomalies.

It looks at neighbours within a defined proximity to identify where either high or low values cluster spatially. Here, statistically significant **hot-spots** are recognised as **areas of high values where other areas within a neighbourhood range also share high values**.

The analysis consists of three steps:

-   Deriving spatial weight matrix

-   Computing Gi statistics

-   Mapping Gi statistics

### Deriving distance-based weight matrix

Getis-Ord defines neighbours based on distance. This means we cannot use the previously derived Queen weight matrix and will need to derive a new set of weight matrix using distance as the measure.

There are two types of distance-based proximity matrix, they are:

-   fixed distance weight matrix; and

-   adaptive distance weight matrix.

#### Deriving Polygon Centroids

We need to associate each polygon with a point before we can make our connectivity graph. It will be a little more complicated than just running *st_centroid()* on the **sf** object: `hunan`. I need the coordinates in a separate data frame for this to work. To do this I will use a mapping function.

The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of `hunan`. Our function will be *st_centroid()*. We will be using *map_dbl()* variation of [map](https://www.rdocumentation.org/packages/purrr/versions/0.2.5/topics/map) from the **purrr** package. **purrr** is loaded when we load **tidyverse**.

To get our longitude values we map the *st_centroid()* function over the geometry column of `hunan` and access the longitude value through double bracket notation \[\[\]\] and 1. This allows us to get only the longitude, which is the first value in each centroid.

```{r}
longitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])
```

We do the same for latitude with one key difference. We access the second value per each centroid with \[\[2\]\].

```{r}
latitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])
```

Now that we have latitude and longitude, I used cbind to put longitude and latitude into the same object. We should check the first few observations to see if things are formatted correctly.

```{r}
coords <- cbind(longitude, latitude)
head(coords, 5)
```

#### Determine the cut-off distance

We need to determine the cut-off distance, within which, two areas are considered neighbours. To ensure that each region has at least one neighbour, we can set the upper limit of the distance band to the maximum first nearest neighbour distance. To do so, we can follow these steps:

-   Return a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using [*knearneigh()*](https://r-spatial.github.io/spdep/reference/knearneigh.html) of **spdep.**

        knearneigh(x, k=1, longlat = NULL, use_kd_tree=TRUE)

-   Convert the knn object returned by *knearneigh()* into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using [*knn2nb()*](https://r-spatial.github.io/spdep/reference/knn2nb.html).

-   Return the length of neighbour relationship edges by using [*nbdists()*](https://r-spatial.github.io/spdep/reference/nbdists.html) of **spdep**. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.

-   Remove the list structure of the returned object by using [**unlist()**](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/unlist).

```{r}
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

The output tells us that the largest first nearest neighbour distance is 61.79km. Using this as the upper limit will ensure that all regions have at least one neighbour.

#### Computing fixed distance-based weight matrix

Now, we can compute the distance-based weight matrix with a distance boundary of 0 to 62km.

```{r}
wm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)
wm_d62
```

From the output, we see that the average number of links is 3.68. This means that on average, the number of links each polygons has 3.68.

Next, we will use *nb2listw()* to convert the nb object into a spatial weights object.

```{r}
wm62_lw <- nb2listw(wm_d62, style ="B")
summary(wm62_lw)
```

### Computing adaptive distance weight matrix

One of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.

To control the numbers of neighbours directly, we can use k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.

As a rule of thumb, we will set k = 8 so that the GDPPC is evaluated within the context of at least 8 neighbours.

```{r}
knn <- knn2nb(knearneigh(coords, k=8))
knn
```

Since we set k=8, the average number of links is also 8 since each county has 8 neighbours.

Again, we will convert the nb object into a spatial weights object.

```{r}
knn_lw <- nb2listw(knn, style = "B")
summary(knn_lw)
```

## Computing Gi Statistics

### Gi Statistics using fixed distance

To compute the Gi statistics, we can use [*localG()*](https://www.rdocumentation.org/packages/spdep/versions/1.1-3/topics/localG) from **spdep** package.

The Gi statistic value returned is a Z-value. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.

```{r}
gi.fixed <- localG(hunan$GDPPC, wm62_lw)
gi.fixed
```

Next, we will join the Gi values to their corresponding hunan sf dataframe.

```{r}
hunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%
  rename(gstat_fixed = as.matrix.gi.fixed.)
```

#### Mapping Gi values with fixed distance weights

The code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix

```{r}
gdppc <- qtm(hunan, 'GDPPC')

Gimap <- tm_shape(hunan.gi) +
  tm_fill(col = "gstat_fixed",
          style = "pretty",
          palette = '-RdBu', 
          title = 'local Gi') + 
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, Gimap, asp = 1, ncol = 2)
```

As mentioned earlier, greater Gi values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters. As we can see there is an area on the top left of the Gimap with high values of Gi. This area could be a hot-spots--areas of high values where other areas within a neighbourhood range also share high values.

### Gi statistics using adaptive distance

The code chunk below are used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e *knn_lw*).

```{r}
fips <- order(hunan$County)
gi.adaptive <- localG(hunan$GDPPC, knn_lw)
hunan.gi <- cbind(hunan, as.matrix(gi.adaptive)) %>%
  rename(gstat_adaptive = as.matrix.gi.adaptive.)
```

#### Mapping Gi values with adaptive distance weights

To visualise the locations of hot spot and cold spot areas, we can use the choropleth mapping functions of **tmap** package.

```{r}
gdppc <- qtm(hunan, "GDPPC")

Gimap <- tm_shape(hunan.gi) + 
  tm_fill(col = "gstat_adaptive",
          style = "pretty",
          palette = "-RdBu",
          title = "local Gi") + 
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, Gimap, asp = 1, ncol = 2)
```

Since the definition of neighbours changed, we can observe differences in identified cold/hot spots between the above chart and the one from the previous section.

## References

Stephanie Glen. "Moran\'s I: Definition, Examples" From [**StatisticsHowTo.com**](https://www.statisticshowto.com/): Elementary Statistics for the rest of us! <https://www.statisticshowto.com/morans-i/>

Tin Seong Kam. "4 Global and Local Measures of Spatial Autocorrelation" From **R for Geospatial Data Science and Analytics** <https://r4gdsa.netlify.app/chap04.html>



