---
title: "Global and Local Measures of Spatial Autocorrelation"
author: "Amelia Chua"
editor: visual
number-sections: true
---

## Overview

In this hands-on exercise, I learned how to compute Global and Local Measure of Spatial Autocorrelation (GLSA) by using **spdep** package. By the end to this hands-on exercise, I was able to:

-   import geospatial data using appropriate function(s) of **sf** package,

-   import csv file using appropriate function of **readr** package,

-   perform relational join using appropriate join function of **dplyr** package,

-   compute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of **spdep** package,

    -   plot Moran scatterplot,

    -   compute and plot spatial correlogram using appropriate function of **spdep** package.

-   compute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions **spdep** package;

-   compute Getis-Ord's Gi-statistics for detecting hot spot or/and cold spot area by using appropriate functions of **spdep** package; and

-   to visualise the analysis output by using **tmap** package.

## Getting Started

### The analytical question

In spatial policy, one of the main development objectives of the local govenment and planners is to **ensure equal distribution of development** in the province. Our task in this study, hence, is to **apply appropriate spatial statistical methods to discover if development are even distributed geographically**.

If the answer is **No**. Then, our next question would be "is there sign of spatial clustering?". And, if the answer for this question is **Yes**, then our next question will be "where are these clusters?"

In this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita or GDPPC) of [Hunan Province](https://en.wikipedia.org/wiki/Hunan), People Republic of China.

### The Study Area and Data

Two data sets will be used in this hands-on exercise, they are:

-   Hunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.

-   Hunan_2012.csv: This csv file contains selected Hunan's local development indicators in 2012.

### Setting the Analytical Tools

The code chunk below installs and loads **sf**, **spdep**, **tmap** and **tidyverse** packages into R environment. [*pacman()*](https://cran.r-project.org/web/packages/pacman/readme/README.html) is a R package management tool. It provides intuitively named functions for the base functions.

```{r}
pacman::p_load(sf, spdep, tmap, tidyverse)
```

## Importing Data into R Environment

The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.

### Import shapefile into R

The code chunk below uses [*st_read()*](https://r-spatial.github.io/sf/reference/st_read.html) of **sf** package to import Hunan shapefile into R. The imported shapefile will be **simple features** object of **sf**.

```{r}
hunan <- st_read(dsn = 'data\\geospatial',
                 layer = 'Hunan')
```

From the output, we can see that there are 88 multipolygons and 7 fields.

### Import csv file into R

```{r}
hunan2012 <- read_csv("data\\aspatial\\Hunan_2012.csv", show_col_types = FALSE)
```

### Performing relational join

The code chunk below will be used to update the attribute table of *hunan*'s SpatialPolygonsDataFrame with the attribute fields of *hunan2012* dataframe. This is performed by using *left_join()* of **dplyr** package.

```{r}
hunan <- left_join(hunan, hunan2012)
```

### Visualising Regional Development Indicator

The code chunk below is used to prepare two stand-alone choropleth maps to visualise the distribution of GDPPC 2012 by using *gtm()* of **tmap** package. The map on the left will be classified using equal intervals and the one on the right will be classified using quantiles.

Then by using *tmap_arrange()* of **tmap** package, we will create a facet map.

Note that:

-   GDPPC refers to Gross Domestic Product per capita.

-   *qtm()* allows us to plot thematic maps quickly.

```{r}

equal <- tm_shape(hunan) +
  tm_fill("GDPPC", 
          n = 5, 
          style = 'equal') + 
  tm_borders(alpha = 0.5) + 
  tm_layout(main.title = 'Equal Interval Classification')

quantile <- tm_shape(hunan) + 
  tm_fill("GDPPC", 
          n = 5, 
          style = 'quantile') + 
  tm_borders(alpha = 0.5) + 
  tm_layout(main.title = "Equal Quantile Classification")

tmap_arrange(equal, quantile, asp = 1, ncol = 2)
```

## Global Spatial Autocorrelation

In this section, I learned how to compute global spatial autocorrelation statistics and how to perform spatial complete randomness test for global spatial autocorrelation.

### Computing Contiguity Spatial Weights

Before we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.

In the code chunk below, [*poly2nb()*](https://r-spatial.github.io/spdep/reference/poly2nb.html) of **spdep** package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. By default, Queen contiguity is applied.

```{r}
wm_q <- poly2nb(hunan, 
                queen = TRUE)
summary(wm_q)
```

The summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two least connected area with only one neighbour.

### Row-standardised weights matrix

Next, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=\"W\"). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighbouring county then summing the weighted income values.

While this is the most intuitive way to summaries the neighbors\' values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data.

Note that other more robust options are available, notably style=\"B\".

```{r}
rswm_q <- nb2listw(wm_q,
                   style = "W",
                   zero.policy = TRUE)
rswm_q
```

### Global Spatial Autocorrelation: Moran's I

In this section, I learned how to perform Moran's I statistical testing by using [*moran.test()*](https://r-spatial.github.io/spdep/reference/moran.test.html) of **spdep**.

    moran.test(x, listw, randomisation=TRUE, zero.policy=NULL,
     alternative="greater", rank = FALSE, na.action=na.fail, spChk=NULL,
     adjust.n=TRUE, drop.EI2=FALSE)

Moran's I describe how features differ from the values in the study area as a whole. If the Moran I (Z-value is):

-   positive (I\>0): Clustered, observations tend to be similar

-   negative (I\<0): Disperse, observations tend to be dissimilar

-   approximately zero: observations arranged randomly over space

We will test the following hypothesis:

-   H0: Observed spatial patterns of values is equally likely as any other spatial pattern i.e. data is randomly disbursed, no spatial pattern

-   H1: Data is more spatially clustered than expected by chance alone.

```{r}
moran.test(hunan$GDPPC,
           listw = rswm_q,
           zero.policy = TRUE,
           na.action = na.omit)
```

Since the p-value \< 0.05, we have sufficient statistical evidence to reject the null hypothesis at the 95% level of confidence. This means that data is more spatially clustered than expected by chance alone. Since Moran I statistic \> 0.300, the observation are clustered, observations tend to be similar.

#### Computing Monte Carlo Moran's I

If we have doubts that the assumptions of Moran's I are true (normality and randomisation), we can use a Monte Carlo simulation to perform a permutation test for Moran's I.

The permutation tests consists of randomly reassigning the attribute values to a cell under the assumption of no spatial pattern. This random assignment is conducted n times. Each time, we will compute the Moran's I to creating an empirical distribution of Moran's I under H0.

The code chunk below performs permutation test for Moran\'s I statistic by using [*moran.mc()*](https://r-spatial.github.io/spdep/reference/moran.mc.html) of **spdep**. A total of 1000 simulation will be performed.

    moran.mc(x, listw, nsim, zero.policy=NULL, alternative="greater",
     na.action=na.fail, spChk=NULL, return_boot=FALSE, adjust.n=TRUE)

We will test the following hypothesis using a one-tailed test:

-   H0: Observed spatial patterns of values is equally likely as any other spatial pattern i.e. data is randomly disbursed, no spatial pattern

-   H1: Data is more spatially clustered than expected by chance alone.

```{r}
set.seed(1234)
bperm = moran.mc(hunan$GDPPC, 
         listw = rswm_q,
         nsim = 999,
         zero.policy = TRUE,
         na.action = na.omit)
bperm
```

Since the **pseudo** p-value \< 0.05, we have sufficient statistical evidence to reject the null hypothesis at the 95% level of confidence. This means that data is more spatially clustered than expected by chance alone.

#### Visualising Monte Carlo Moran's I

We can examine the simulated Moran\'s I test statistics in greater detail through descriptive statistics and plotting the distribution of the statistical values as a histogram by using the code chunks below.

The mean gives the average of Moran's I for all simulated distributions.

```{r}
mean(bperm$res[1:999])
```

The variance of Moran\'s I for all simulated distributions can be computed using this code chunk.

```{r}
var(bperm$res[1:999])
```

```{r}
summary(bperm$res[1:999])
```

```{r}
hist(bperm$res,
     freq = TRUE,
     breaks = 20,
     xlab = "Simulated Moran's I")
abline(v=0, 
       col = 'red')
abline(v=0.30075, #actual moran's I
       col = 'blue')
```

From the output above, we can see that the distribution of the simulated values of Moran's I is slightly skewed to the right. The blue line above indicates the actual value of Moran's I, which is near the extremes of the distribution. This suggests that there is evidence of positive autocorrelation i.e. cluster. ([Reference](https://gis.stackexchange.com/questions/161887/significance-test-for-morans-i-using-monte-carlo-simulation))

We can also plot the above graph using **ggplot2** package. To do so, we must first convert the results into a dataframe.

```{r}
df <- as.data.frame(bperm$res)
colnames(df) <- c("Simulated Moran's I")
```

```{r}
ggplot(df, aes(x=`Simulated Moran's I`)) + 
  geom_histogram(color = "darkblue", fill = "lightblue", bins = 20) +
  ylab('Frequency')
```

### Global Spatial Autocorrelation: Geary's C

In this section, I learned how to perform Geary\'s C statistics testing by using appropriate functions of **spdep** package.

#### Geary's C Test

Geary's C describe how features differ from their immediate neighbours. If the Geary's C (Z-value is):

-   Large (c\>1): Dispersed, observations tend to be dissimilar

-   Small (c\<1): Clustered, observations tend to be similar

-   c = 1: observations arranged randomly over space

We will test the following hypothesis:

-   H0: Observed spatial patterns of values is equally likely as any other spatial pattern i.e. data is randomly disbursed, no spatial pattern

-   H1: Data is more spatially clustered than expected by chance alone

The code chunk below performs Geary\'s C test for spatial autocorrelation by using [*geary.test()*](https://r-spatial.github.io/spdep/reference/geary.test.html) of **spdep**.

    geary.test(x, listw, randomisation=TRUE, zero.policy=NULL,
        alternative="greater", spChk=NULL, adjust.n=TRUE)

```{r}
geary.test(hunan$GDPPC, listw = rswm_q)
```

Since the p-value = 0.0001526 \< 0.05, we have sufficient statistical evidence to reject the null hypothesis at the 95% level of confidence. This means that data is more spatially clustered than expected by chance alone.

#### Computing Monte Carlo Geary's C

The code chunk below performs permutation test for Geary\'s C statistic by using [*geary.mc()*](https://r-spatial.github.io/spdep/reference/geary.mc.html) of **spdep**.

```{r}
set.seed(1234)
bperm = geary.mc(hunan$GDPPC,
                 listw = rswm_q,
                 nsim = 999)
bperm
```

Since the **pseudo** p-value = 0.001 \< 0.05, we have sufficient statistical evidence to reject the null hypothesis at the 95% level of confidence. This means that data is more spatially clustered than expected by chance alone.

#### Visualising the Monte Carlo Geary's C

We can examine the simulated Geary's C test statistics in greater detail through descriptive statistics and plotting the distribution of the statistical values as a histogram by using the code chunks below.

The mean gives the average of Geary's C for all simulated distributions.

```{r}
mean(bperm$res[1:999])
```

The variance of Geary's C for all simulated distributions can be computed using this code chunk.

```{r}
var(bperm$res[1:999])
```

```{r}
summary(bperm$res[1:999])
```

```{r}
hist(bperm$res,
     freq = TRUE,
     breaks = 20,
     xlab = "Simulated Geary's C")
abline(v=1, 
       col = 'red')

```

From the output above, we can see that the distribution of the simulated values of Moran's I fairly normally distributed.

## Spatial Correlogram

Spatial correlograms are great to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran\'s I or Geary\'s c) against distance.Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.

### Compute Moran's I correlogram

In the code chunk below, [*sp.correlogram()*](https://r-spatial.github.io/spdep/reference/sp.correlogram.html) of **spdep** package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran\'s I. The **plot()** of base Graph is then used to plot the output.

    sp.correlogram(neighbours, var, order = 1, method = "corr",
     style = "W", randomisation = TRUE, zero.policy = NULL, spChk=NULL)
    # S3 method for spcor
    plot(x, main, ylab, ylim, ...)
    # S3 method for spcor
    print(x, p.adj.method="none", ...)

```{r}
MI_corr <- sp.correlogram(wm_q, #note that we used the original weights matrix
                          hunan$GDPPC,
                          order = 6,
                          method = 'I',
                          style = 'W')
plot(MI_corr)
```

Next, let's examine the full analysis report and view which values are statistically significant.

```{r}
print(MI_corr)
```

From the output, we see that with the exception of Lag 4, the rest of the results are statistically significant at the 95% level of confidence.

### Compute Geary's C correlogram and plot

In the code chunk below, *sp.correlogram()* of **spdep** package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary\'s C. The **plot()** of base Graph is then used to plot the output.

```{r}
GC_corr <- sp.correlogram(wm_q,
                          hunan$GDPPC,
                          order = 6, 
                          method = "C",
                          style = "W")
plot(GC_corr)
```

Next, let's examine the full analysis report and view which values are statistically significant.

```{r}
print(GC_corr)
```

From the output, we see that with the exception of Lag 3, 4 and 6, the rest of the results are statistically significant at the 95% level of confidence.

## Cluster and Outlier Analysis

Local Indicators of Spatial Association or LISA are statistics that **evaluate the existence of clusters in the spatial arrangement of a given variable**. For instance if we are studying cancer rates among census tracts in a given city, local clusters in the rates mean that there are areas that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.

In this section, I learned how to apply appropriate Local Indicators for Spatial Association (LISA), especially local Moran\'s I to detect cluster and/or outlier from GDP per capita 2012 of Hunan Province, PRC.

### Computing local Moran's I

To compute local Moran\'s I, the [*localmoran()*](https://r-spatial.github.io/spdep/reference/localmoran.html) function of **spdep** will be used. It computes *Ii* values, given a set of *zi* values and a listw object providing neighbour weighting information for the polygon associated with the zi values.

The code chunks below are used to compute local Moran\'s I of *GDPPC2012* at the county level.

```{r}
localMI <- localmoran(hunan$GDPPC, rswm_q)
head(localMI)
```

*localmoran()* returns a matrix of values whose columns are:

-   Ii: the local Moran\'s I statistics

-   E.Ii: the expectation of local moran statistic under the randomisation hypothesis

-   Var.Ii: the variance of local moran statistic under the randomisation hypothesis

-   Z.Ii:the standard deviation of local moran statistic

-   Pr(): the p-value of local moran statistic

The code chunk below list the content of the local Moran matrix derived by using [*printCoefmat()*](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/printCoefmat).

```{r}
fips <- order(hunan$County) #order in alphabetical order, returns index of the variable
printCoefmat(data.frame(localMI[fips,],
                        row.names=hunan$County[fips]), check.names=FALSE)
```

#### Mapping the local Moran's I

Before mapping the local Moran\'s I map, I would append the local Moran\'s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame. The code chunks below can be used to perform the task.

```{r}
hunan.localMI <- cbind(hunan, localMI) %>%
rename(Pr.Ii = Pr.z....E.Ii..)
```

#### Mapping local Moran's I values

Using choropleth mapping functions of **tmap** package, we can plot the local Moran\'s I values by using the code chinks below.

```{r}
localMI.map <- tm_shape(hunan.localMI) + 
                  tm_fill(col = "Ii",
                          style = 'pretty',
                          title = "Local Moran Statistics") + 
                  tm_borders(alpha = 0.5)
localMI.map
```

#### Mapping local Moran's I p-values

The choropleth above shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.

The code chunks below produce a choropleth map of Moran\'s I p-values by using functions of **tmap** package.

```{r}
pvalue.map <- tm_shape(hunan.localMI) + 
                tm_fill(col = "Pr.Ii",
                       breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
                       palette = "-Blues",
                       title = "Local Moran's I p-values") + 
                tm_borders(alpha = 0.5)

pvalue.map
```

#### Mapping both local Moran's I values and 

For effective interpretation, it is better to plot both the local Moran\'s I values map and its corresponding p-values map next to each other.

```{r}
tmap_arrange(localMI.map, pvalue.map, asp = 1, ncol = 2)
```

## References

Stephanie Glen. "Moran\'s I: Definition, Examples" From [**StatisticsHowTo.com**](https://www.statisticshowto.com/): Elementary Statistics for the rest of us! <https://www.statisticshowto.com/morans-i/>

