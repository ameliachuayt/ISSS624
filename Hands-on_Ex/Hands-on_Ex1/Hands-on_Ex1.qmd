---
title: "Hands-on Exercise 1: Geospatial Data Wranglingand Choropleth Mapping with R"
editor: visual
---

## 1.1 Overview of Part I

In the first of this two-part hands-on exercise, I learned how to import, and wrangle geospatial data using appropriate R packages.

## 1.2 Data Acquisition

## 1.3 Getting Started

The code chunk below installs and loads sf and tidyverse packages into R environment. [*pacman()*](https://cran.r-project.org/web/packages/pacman/readme/README.html) is a R package management tool. It provides intuitively named functions for the base functions.

```{r}
pacman::p_load(sf, tidyverse)

```

An alternate way to install and import the libraries is as follows:

```{r}
packages = c('sf','tidyverse')
for (p in packages){
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p, character.only = T)
}
```

## 1.4 Import Geospatial Data

In this section, I learned how to import the following geospatial data into R by using [*st_read()*](https://r-spatial.github.io/sf/reference/st_read.html) of **sf** package:

-   `MP14_SUBZONE_WEB_PL`, a **polygon feature layer** in ESRI shapefile format,

-   `CyclingPath`, a **line feature layer** in ESRI shapefile format, and

-   `PreSchool`, a **point feature layer** in kml file format.

### 1.4.1 Import polygon feature date in shapefile format

The code chunk below uses *st_read()* function of **sf** package to import `MP14_SUBZONE_WEB_PL` shapefile into R as a polygon feature data frame.

When the input geospatial data is in shapefile format (*.shp*), two arguments will be used: `dsn` to define the data path and `layer` to provide the shapefile name. No extensions such as .shp, .dbf, .prj and .shx are reqquired.

```{r}
mpsz = st_read(dsn="data\\geospatial",
               layer = "MP14_SUBZONE_WEB_PL")

```

The output shows that there are 323 multipolygon features and 15 fields. The Bounding box provides the x extend and y extend of the data.

### 1.4.2 Import polyline feature data in shapefile form

The code chunk below uses *st_read()* function of **sf** package to import `CyclingPath` shapefile into R as a **line feature** data frame.

```{r}
cyclingpath = st_read(dsn = "data\\geospatial",
                      layer = 'CyclingPath')
```

The output shows that there are 1625 features and 2 fields in `CyclingPath` linestring feature data frame and it is in **svy21** projected coordinates system.

### 1.4.3 Import GIS data in kml format

The code chunk below uses *st_read()* function of **sf** package to import `pre-schools-location-kml` kml file into R as a **point feature** layer. Since we are dealing with a kml file, instead of specifying `dsn` and `layer`, we specify the complete path and file extension.

```{r}

preschool = st_read("data\\geospatial\\pre-schools-location-kml.kml")

```

The output reveals that `preschool` is a point feature data frame (see "Geometry type: POINT'"). There are a total of 1359 features and 2 fields. Different from the previous two simple feature data frame, preschool is in wgs84 coordinates system (see "Geodetic CRS: WGS 84").

## 1.5 Checking the Content of A Simple Feature Data Frame

In the section, I learned different ways to retrieve information related to the contents of a simple feature data frame.

### 1.5.1 Working with *st_geometry()*

The column in the sf data.frame that contains the geometries is a list, of class `sfc`. We can retrieve the geometry list-column in this case by mpsz\$geom or mpsz\[\[1\]\], but the more general way uses *st_geometry()* as shown in the code chunk below.

```{r}
st_geometry(mpsz)

```

The output displays basic information of the feature class such as type of geometry, the geographic extent of the features and the coordinate system of the data.

### 1.5.2 Working with *glimpse().*

To learn more about the associated attribute information in the data frame, we can use ***glimpse()*** of dplyr.

```{r}
glimpse(mpsz)
```

As we can see in the output, ***glimpse()*** reveals the data type of each field.

For example, `FMEL-UPD_D` is in date data '\<date\>', and `X_ADDR`, `Y_ADDR` are in double precision values '\<dbl\>'

### 1.5.3 Working with *head()*

Sometimes, we would like to examine complete information of a feature object. We can use [*head()*](https://www.rdocumentation.org/packages/utils/versions/3.6.2/topics/head) of Base R to achieve this. The argument `n` allows us to indicate the number of records to display.

```{r}
head(mpsz, n=5)
```

## 1.6 Plotting the Geospatial Data

In geospatial analytics, we are definitely interested to visualise geospatial features. *plot()* provides a quick and simply way to visualise the data at hand.

```{r}
plot(mpsz)
```

The default plot of sf object is a multi-plot of all attributes, up to a maximum limit (in this case, it is 9 out of 15) as shown above.

We can also choose to plot only the geometry by using the code chunk below.

```{r}
plot(st_geometry(mpsz))
```

We can also choose to plot the sf object by using a specific attribute.

```{r}
plot(mpsz["PLN_AREA_N"])
```

As mentioned earlier, *plot()* is meant for plotting the geospatial object for quick look. For high cartographic quality plot with more customisation options, tmap or other packages should be used.

## 1.7 Working with Projection

In order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system. **Projection Transformation** is the process of projecting a simple feature data frame from one coordinate system to another coordinate system.

### 1.7.1 Assigning EPSG code to a simple feature data frame

[EPSG](https://support.virtual-surveyor.com/en/support/solutions/articles/1000261353-what-is-an-epsg-code-#:~:text=EPSG%20stands%20for%20European%20Petroleum,spheroids%2C%20units%20and%20such%20alike.) stands for European Petroleum Survey Group and is an organisation that maintains a public registry of geodetic parameter database with standard codes--the EPSG codes.

One common issue faced during importing geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.

We can examine the coordinate system of `mpsz` simple feature data frame by using *st_crs()* of *sf* package as shown in the code chunk below.

```{r}
st_crs(mpsz)
```

Although the `mpsz` data frame is projected in 'svy21', when we read till the end of the print it indicates that EPSG is 9001, which is wrong. See the last line where "ID\["EPSG",9001\]".

The correct/corresponding EPSG code for 'svy21' should be '3414'. We can assign the correct EPSG code using *st_set_crs()* of **sf** package.

```{r}
mpsz3414 <- st_set_crs(mpsz, 3414)
```

To confirm the change, we can check the coordinate system or CSR again.

```{r}
st_crs(mpsz3414)
```

Note that the EPSG code is 3414. See last line where "ID\["EPSG",3414\]".

### 1.7.2 Transforming the projection of preschool from wgs84 to svy21

In this sub-section, we will learn how to transform original data from **geographic coordinate system** to **projected coordinate system**. We need to do this transformation because the geographic coordinate system is inappropriate if the analysis require the use of distance and/or area measurements.

For the `preschool` simple feature data frame, the output of the code chunk below tells us that it is in the wgs84 coordinate system (see "Geodetic CRS: WGS 85").

```{r}
st_geometry(preschool)
```

Instead of using *st_set_crs()* like we did in the previous section, we must use *st_transform()* of the sf package. This is because we need to reproject `preschool` from one coordinate system to another coordinate system **mathematically**.

```{r}
preschool3414 <- st_transform(preschool,
                              crs = 3414)
```

> Note: In practice, we need to find out the appropriate project coordinate system to use before performing the projection transformation.

Let's check if the transformation is complete.

```{r}
st_geometry(preschool3414)
```

From the output, we can see that it is in the svy21 projected coordinate system now (see "Projected CRS: SVY21 / Singapore TM). Also, the Bounding box values are greater than 0-360 range of decimal degree commonly used by most of the geographic coordinate systems.

## 1.8 Importing and Converting Aspatial Data

It is common to have data such as `listing` of inside Airbnb. Such data are called aspatial data. They are not geospatial data, however, among the data fields, there are two fields that capture the x- and y- coordinates of the data points.

In this section, I learned to import aspatial data in R environment and save it as a [tibble](https://r4ds.had.co.nz/tibbles.html)data frame. Then, I will convert it into a simple feature data frame.

### 1.8.1 Importing aspatial data

`listings.csv` data set is in csv format and we will use *read_csv()* or **readr** package to import the file. The output R object is called `listings` and is a tibble data frame.

```{r}
listings <- read_csv('data\\aspatial\\listings.csv')
```

Let's examine if the import was completely correctly.

```{r}
list(listings)
```

The output reveals that `listing` tibble data frame consists of 4252 rows and 16 columns. Two useful fields we are going to use in the next phase are `latitude` and `longitude`. Note that they are in decimal degree format. As a best guess, we will assume that the data is in **wgs84** Geographic Coordinate System

Note that *list()* instead of [glimpse()](https://dplyr.tidyverse.org/reference/glimpse.html) was used above. In the code chunk below, we can also print the features of the data using *glimpse().* In *glimpse(),* the columns run down the page and data runs across, enabling us to see all the columns easily.

```{r}
glimpse(listings)
```

### 1.8.2 Create simple feature dataframe from aspatial dataframe

The code chunk below converts `listing` data frame into a simple feature data frame by using [*st_as_sf()*](https://r-spatial.github.io/sf/reference/st_as_sf.html) of **sf** packages

```{r}
listings_sf <- st_as_sf(listings,
                        coords = c("longitude","latitude"), #x-coord first, then y-coord
                        crs=4326) %>% #provide coordinates system in epsg format
                                      #EPSG:4326 is wgs84
                                      #EPSG:3414 is Singapore's SVY21 Projected Coordinate System
  st_transform(crs = 3414)
```

Several things to take note of from the arguments above:

-   *coords* argument requires us to input column name of x-coordinate first, followed by column name of y-coordinate

-   crs argument requires us to provide the coordinates system in epsg format. [EPSG: 4326](https://epsg.io/4326) is wgs84 Geographic Coordinate System and [EPSG: 3414](https://epsg.io/3414) is Singapore SVY21 Projected Coordinate System. We can search for other country's epsg code by referring to [epsg.io](https://epsg.io/).

-   *%\>%* is used to nest *st_transform()* to transform the newly created simple feature data frame into svy21 projected coordinates system.

Let's examine the content of the newly created simple feature data frame. Note that there is a new column `geometry` that has been added. Also, the `longitude` and `latitude` columns have been dropped.

```{r}
glimpse(listings_sf)
```

## 1.9 Geo-processing with sf package

Besides providing functions to handling (i.e. importing, exporting, assigning projection, transforming projection etc) geospatial data, **sf** package also offers a wide range of geoprocessing (also known as GIS analysis) functions.

In this section, I learned how to perform two commonly used geoprocessing functions:

-   [buffering](https://www.gislounge.com/buffers-in-gis/) and

-   point in polygon count

### 1.9.1 Buffering

Buffering involves measuring the distance outward in all directions from an object. The output is a polygon.

To illustrate how buffering works, how is a hypothetical scenario:

::: {.callout-note appearance="simple" icon="false"}
The authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path.

Task: Determine the extent of the land that needs to be acquired and their total area.
:::

Steps to solve:

**Step 1**: **Compute the 5-meter buffers around the cycling paths**

```{r}
buffer_cycling <- st_buffer(cyclingpath,
                            dist = 5, #5 metres
                            nQuadSegs = 30)
```

**Step 2: Calculate area of buffers**

As mentioned earlier, the output of buffering is polygons. So here, we can create a new column `AREA` to store the values of the areas of polygons

```{r}
buffer_cycling$AREA <- st_area(buffer_cycling)
```

**Step 3: Derive Total Land Area**

To do this, we can easily use *sum()* of Base R

```{r}
sum(buffer_cycling$AREA)
```

### 1.9.2 Point-in-polygon Count

We can also count the frequency of observations within a polygon. To illustrate this, we have another hypothetical situation

::: {.callout-note icon="false"}
A pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.

Task: Find out the numbers of pre-schools in each Planning Subzone and the density per square metres.
:::

**Step 1: Identify pre-schools located in each Subzone and Calculate number of pre-schools in each subzone**

We can use *st_interesects()* to identify which subzones pre-schools are located in and *lengths()* to count the number of pre-schools that fall inside each subzone.

```{r}
mpsz3414$`PreSch Count` <- lengths(st_intersects(mpsz3414, preschool3414))
```

Check descriptive statistics using the below code chunk.

```{r}
summary(mpsz3414$`PreSch Count`)
```

We can also list the subzone with the most pre schools using *top_n()* of **dplyr** package. We can change the argument within *top_n()* according to requirements e.g., Top 3, 5, or 10, etc.

```{r}
top_n(mpsz3414, 1, `PreSch Count`)
```

**Step 2: Derive area of each subzone**

The code chunk below uses *st_area()* of **sf** package to derive the area of each subzone. We are creating a new column `Area` to store the area values.

```{r}
mpsz3414$Area <- mpsz3414 %>% 
  st_area()
```

**Step 3: Calculate Density**

We can simply calculate the density by using *mutate()* of **dplyr** package. A new column `PreSch Density` is created.

```{r}
mpsz3414 <- mpsz3414 %>%
  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)
```

## 1.10 Exploratory Data Analysis (EDA)

In this section, I learned appropriate [ggplot2](https://ggplot2.tidyverse.org/) functions to create function yet truthful statistical graphs for EDA purposes.

#### 1.10.1 Distribution of Pre-school Density in Subzones of Singapore using Histograms

Conventionally, *hist()* of R Graphics can be used to plot a histogram of the distribution of pre-school density. While *hist()*'s syntax is easy to use, the output does not meet publication quality and it has limited room for customisation.

```{r}
hist(mpsz3414$`PreSch Density`) 
```

Let's retry to **ggplot2** functions instead.

```{r}
ggplot(data=mpsz3414,
       aes(x=as.numeric(`PreSch Density`))) +
  geom_histogram(bins=20,
                 color="black",
                 fill = "light blue") + 
  labs(title = "Are pre-schools evenly distributed in Singapore?",
       subtitle = "There are many planning sub-zones with a single pre-school, on the other hand, \nthere are two planning sub-zones with at least 20 pre-schools",
       x = "Pre-school density (per km sq)",
       y = "Frequency")
```

#### 1.10.2 Relationship between Pre-school Density and Pre-school Count using Scatterplot

DIY: Conventionally, *plot()* of R Graphics can be used to plot a scatterplot to reveal the relationship between pre-school density and pre-school count.

```{r}
plot(mpsz3414$`PreSch Density`, mpsz3414$`PreSch Count`, main="Pre-school Count vs Pre-school Density",
    pch=19)
```

However, we may also opt to use **ggplot2** for it has better customisation capabilities.

```{r}
library(units)
ggplot(data=mpsz3414, aes(x=`PreSch Density`, y=`PreSch Count`))+
  geom_point()+ 
  labs(x = "Pre-school density (per km sq)",
       y = "Pre-school count")
```

## 2.1 Overview Of Part II

In the second of this two-part hands-on exercise, I learned how to plot functional and truthful choropleth maps by using an R package called **tmap** package.

Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.

## 2.2 Data Acquisition

Two data set will be used to create the choropleth map. They are:

-   Master Plan 2014 Subzone Boundary (Web) (i.e. `MP14_SUBZONE_WEB_PL`) in ESRI shapefile format. It can be downloaded at [data.gov.sg](https://data.gov.sg/) This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.

-   Singapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. `respopagesextod2011to2020.csv`). This is an aspatial data fie. It can be downloaded at [Department of Statistics, Singapore](https://www.singstat.gov.sg/) Although it does not contain any coordinates values, but it's PA and SZ fields can be used as unique identifiers to geocode to `MP14_SUBZONE_WEB_PL` shapefile.

## 2.3 Getting Started & Importing Data

## 2.3.1 Getting Started

The key R package for this hands-on exercise is [**tmap**](https://cran.r-project.org/web/packages/tmap/) package in R. We will also be using four other R packages:

-   [**readr**](https://readr.tidyverse.org/) for importing delimited text file,

-   [**tidyr**](https://tidyr.tidyverse.org/) for tidying data,

-   [**dplyr**](https://dplyr.tidyverse.org/) for wrangling data and

-   [**sf**](https://cran.r-project.org/web/packages/sf/) for handling geospatial data

Three out of the four are packages (**readr, tidyr** and **dplyr**) are part of the **tidyverse** package. Therefore, we can just load the **tidyverse** package instead of all three packages.

The code chunk below loads sf, tmap and tidyverse packages into R environment.

```{r}
pacman::p_load(sf, tmap, tidyverse)

```

## 2.3.2 Importing Geospatial Data into R

We can use *st_read()* of **sf** package to import MP14_SUBZONE_WEB_PL shapefile in R as a simple feature data frame called `mpsz`.

```{r}
mpsz <- st_read(dsn="data\\geospatial",
                layer='MP14_SUBZONE_WEB_PL')
```

Examine the content of *mpsz* using the code chunk below.

```{r}
mpsz
```

Interestingly, only the first ten records will be displayed.

On the other hand, we can also use *head()* to specify the number of rows to return (must be less than 10).

```{r}
head(mpsz, 3)
```

### 2.3.3 Import Attribute Data

Next, I imported *respopagsex2000to2018.csv* file into RStudio and saved the file into an R dataframe called *popagsex* using *read_csv()* function of **readr** package as shown in the code chunk below.

```{r}
popdata <- read_csv('data\\aspatial\\respopagesextod2011to2020.csv')
```

### 2.3.4 Data Preparation

I am interested to visualise population demographics in the Year 2020. Before a thematic map can be prepared, I need to prepare a data table with Year 2020 values. The following variables will be required for this tasks: `PA`, `SZ`, `YOUNG`, `ECONOMY ACTIVE,` `AGED`, `TOTAL`, `DEPENDENCY`.

-   `PA`: Planning Area

-   `SZ`: Planning Subzone

-   `YOUNG`: age group 0 to 4 until age groyup 20 to 24,

-   `ECONOMY ACTIVE`: age group 25-29 until age group 60-64,

-   `AGED`: age group 65 and above,

-   `TOTAL`: all age group, and

-   `DEPENDENCY`: the ratio between young and aged against economy active group.

As we can see, we will need to wrangle the data set and derive new columns like `YOUNG` and `AGED`.

#### 2.3.4.1 Data Wrangling

The following data wrangling and transformation functions were used:

-   [*pivot_wider()*](https://tidyr.tidyverse.org/reference/pivot_wider.html) of **tidyr** package, and

    -   this was used to pivot row values like age to columns. It "widens" data, increasing the number of columns and decreasing the number of rows.

-   *mutate()*, *filter()*, *group_by()* and *select()* of **dplyr** package

```{r}
popdata2020 <- popdata %>%
  filter(Time == 2020) %>%
  group_by(PA, SZ, AG) %>%
  summarise(`POP` = sum(`Pop`)) %>%
  ungroup()%>%
  pivot_wider(names_from=AG, 
              values_from=POP) %>%
  mutate(YOUNG = rowSums(.[3:6])
         +rowSums(.[12])) %>%
mutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+
rowSums(.[13:15]))%>%
mutate(`AGED`=rowSums(.[16:21])) %>%
mutate(`TOTAL`=rowSums(.[3:21])) %>%  
mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)
/`ECONOMY ACTIVE`) %>%
  select(`PA`, `SZ`, `YOUNG`, 
       `ECONOMY ACTIVE`, `AGED`, 
       `TOTAL`, `DEPENDENCY`)
```

#### 2.3.4.2 Joining attribute data and geospatial data

We need to convert the `PA` and `SZ` values to uppercase.

```{r}
popdata2020 <- popdata2020 %>%
  mutate_at(.vars = vars(PA, SZ), 
          .funs = funs(toupper)) %>%
  filter(`ECONOMY ACTIVE` > 0)
```

Next, *left_join()* of **dplyr** is used to join the geographical data and attribute table using planning subzone name e.g. *SUBZONE_N* and *SZ* as the common identifier.

```{r}
mpsz_pop2020 <- left_join(mpsz, popdata2020,
                          by = c("SUBZONE_N" = "SZ"))
```

Write the resulting file into a .rds file.

```{r}
write_rds(mpsz_pop2020, "data\\rds\\mpszpop2020_amelia.rds")
```

## 2.4 Choropleth Mapping Geospatial Data Using tmap package

There are two approaches to prepare thematic map using *tmap*, they are:

-   Plotting a thematic map quickly by using *qtm()*.

-   Plotting highly customisable thematic map by using tmap elements.

### 2.4.1 Plotting choropleth quickly using *qtm()*

*qtm()* of **tmap** package provides a quick and concise visualisation.

```{r}
tmap_mode('plot')
qtm(mpsz_pop2020,
    fill = "DEPENDENCY")
```

### 2.4.2 Creating choropleth map using tmap's elements

While *qtm()* can be used to get quick visualisation, the downside is that aesthetics of individual layers are harder to control. To get a high quality cartographic choropleth map, I will use **tmap**'s drawing elements.

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY", 
          style = "quantile", 
          palette = "Blues",
          title = "Dependency ratio") +
  tm_layout(main.title = "Distribution of Dependency Ratio by planning subzone",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2) +
  tm_credits("Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\n and Population data from Department of Statistics DOS", 
             position = c("left", "bottom"))

```

The steps to creating the above map will be detailed in this sub-section.

#### 2.4.2.1 Drawing a base map

The basic building block of **tmap** is *tm_shape()* followed by one or more layer elemments such as *tm_fill()* and *tm_polygons()*:

-   tm_shape() defines the input data

-   tm_polygons() draws the planning subzone polygons

```{r}
tm_shape(mpsz_pop2020) +
  tm_polygons()
```

#### 2.4.2.2 Drawing a choropleth map using *tm_polygons()*

To draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we assign the target variable such as *Dependency* to *tm_polygons()*.

By default, missing values will be shaded in grey.

```{r}
tm_shape(mpsz_pop2020)+
  tm_polygons("DEPENDENCY")
```

#### 

2.4.2.3 Drawing a choropleth map using *tm_fill()* and *tm_border*()

-   tm_fill(): shades the polygons using the default colour scheme

-   *tm_border():* Add borders to the polygons. The arguments are as follows:

    -   *alpha* specifies the transparency or opaqueness of the borders. By default, the alpha value of the col is used (normally 1 i.e. not transparent). There

    -   *col* specifies the border colour,

    -   *lwd* specifies the border line width. The default is 1, and

    -   *lty* specifies the border line type. The default is "solid".

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY")+
  tm_borders(lwd = 0.1,  alpha = 1)
```

### 2.4.3 Data classification methods of **tmap**

Choropleth maps employ some methods of data classification so to take a large number of observations and group them into data ranges or classes.

**tmap** provides a total ten data classification methods, namely: *fixed*, *sd*, *equal*, *pretty* (default), *quantile*, *kmeans*, *hclust*, *bclust*, *fisher*, and *jenks*.

To define a data classification method, the *style* argument of *tm_fill()* or *tm_polygons()* will be used.

#### 2.4.3.1 Plotting choropleth maps with built-in classification methods

The code chunk below shows a quantile data classification that used 5 classes (*n* = 5). This method classifies data into a certain number of categories with an equal number of units in each category.

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5)
```

In the code chunk below, *equal* data classification method is used. This method sets the value ranges in each category equal in size.

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY",
          n = 5,
          style = "equal") +
  tm_borders(alpha = 0.5)
```

DIY: We can see that the distribution of **quantile** data classification method are more evenly distributed than **equal** data classification method.

Let's us examine other types of classification methods:

-   Top Left: pretty (default),

-   Top Right: equal,

-   Bottom Left: jenks and

-   Bottom Right: kmeans.

```{r}
tm_shape(mpsz_pop2020)+ 
  tm_fill(c("DEPENDENCY","DEPENDENCY","DEPENDENCY","DEPENDENCY"),,
              style = c("pretty", "equal","jenks","kmeans"), 
              palette = list("Blues","Oranges","Reds","Greens")) +
  tm_layout(legend.position = c("right", "bottom"))+
  tm_borders(alpha = 0.2)
```

We can observe that pretty and equal gives similar distributions and not as even as the other two. Comparing jenks and kmeans classification methods, we can see that kmeans is more evenly distributed.

DIY: The below code chunk uses the quantile classification method with different numbers of classes: 2 (top left), 6 (top right), 10 (bottom left), 20 (bottom right).

```{r}
tm_shape(mpsz_pop2020)+ 
  tm_fill(c("DEPENDENCY","DEPENDENCY","DEPENDENCY","DEPENDENCY"),
              n = c(2,6,10,20),
              style = c("quantile", "quantile","quantile","quantile"), 
              palette = list("Blues","Oranges","Reds","Greens")) +
  tm_layout(legend.position = c("right", "bottom"))+
  tm_borders(alpha = 0.2)
```

Unsurprisingly, we can see that as the number of classes increases, the more distributed the data is. Although the differences between the chart diminishes as the number of classes increase--for e.g., classes 10 and 20 are quite similar.

#### 
2.4.3.2 Plotting choropleth map with custom break

We can set breakpoints using the *breaks* argument in *tm_fill().* For **tmap**, breaks include a minimum and maximum. Therefore, to have n categories, n+1 elements must be specified in **ascending order**.

First, some descriptive stats

```{r}
summary(mpsz_pop2020$DEPENDENCY)
```

With reference to the above, we set break points at 0.00 (min), 0.60, 0.70, 0.80, 0.90, 1.00 (max).

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY",
          breaks = c(0.00, 0.60, 0.70, 0.80, 0.90, 1.00)) +
  tm_borders(alpha = 0.5)
```

2.4.4 Colour Scheme

**tmap** supports colour ramps either defined by the user or a set of predefined colour ramps from the **RColorBrewer** package

#### 2.4.4.1 Using **ColorBrewer** Palette

To change the colour palette, we assign the preferred colour to *palette* argument of *tm_fill()* as shown below.

```{r}
tm_shape(mpsz_pop2020) +
  tm_fill("DEPENDENCY",
          n = 6, 
          style = "quantile",
          palette = "Blues") +
  tm_borders(alpha = 0.5)
```

We can reverse the colour shades by adding '-' in the *palette* argument.

```{r}
tm_shape(mpsz_pop2020) +
  tm_fill("DEPENDENCY",
          style = "quantile",
          palette = "-Blues") +
  tm_borders(alpha = 0.5)
```

### 2.4.5 Map Layouts

Map layout refers to the combination of all map elements into a cohesive map. Map elements includes: objects to be mapped,title, scale bar, compass, margins and aspects ratios.

#### 2.4.5.1 Map Legend

In **tmap,** *legend* options allow us to change appearance, position and format of the legend.

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY", 
          style = "jenks", 
          palette = "Blues", 
          legend.hist = TRUE, 
          legend.is.portrait = TRUE,
          legend.hist.z = 0.1) +
  tm_layout(main.title = "Distribution of Dependency Ratio by planning subzone \n(Jenks classification)",
            main.title.position = "center",
            main.title.size = 1,
            legend.height = 0.45, 
            legend.width = 0.35,
            legend.outside = FALSE,
            legend.position = c("right", "bottom"),
            frame = FALSE) +
  tm_borders(alpha = 0.5)
```

#### 2.5.4.2 Map Style

In **tmap,** we can change a wide variety of layout settings using *tmap_style().* The *classic* style is used here. Other available styles are: "white", "gray", "natural", "cobalt", "col_blind", "albatross", "beaver", "bw", "watercolor"

```{r}
tm_shape(mpsz_pop2020) + 
  tm_fill("DEPENDENCY",
          style = "quantile", 
          palette = "-Greens") + 
  tm_borders(alpha = 0.5) +
  tmap_style("classic")
```

#### 2.4.5.3 Cartographic Furniture

**tmap** also provides arguments to draw other map furniture like compass, scale bar and grid lines.

```{r}
tm_shape(mpsz_pop2020) + 
  tm_fill("DEPENDENCY",
          style = "quantile", 
          palette = "Blues",
          title = "No. of persons") + 
  tm_layout(main.title = "Distribution of Dependency Ratio \nby planning subzone",
            main.title.position = "center",
            main.title.size = 1.2, 
            legend.height = 0.45,
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) + 
  tm_compass(type="8star", size = 2) + 
  tm_scale_bar(width = 0.15) + 
  tm_grid(lwd = 0.1, alpha = 0.2) + 
  tm_credits("Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\n and Population data from Department of Statistics DOS", 
             position = c("left", "bottom"))
```

To reset to the default style, use the below.

```{r}
tmap_style("white")
```

### 2.4.6 Drawing Small Multiple Choropleth Maps of Facet Maps

**Small multiple maps** or **facet maps** are composed of many maps arranged side-by-side or stacked vertically. Using facet maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.

In **tmap,** small multiple maps can be plotted in three ways:

-   by assigning multiple values to at least one of the asthetic arguments

-   by defining a group-by variable in *tm_facets()*, and

-   by creating multiple stand-alone maps with *tmap_arrange()*.

#### 2.4.6.1 By assigning multiple values to at least one of the aesthetic arguments

I created facet maps by defining *col* in *tm_fill().*

```{r}
tm_shape(mpsz_pop2020) + 
  tm_fill(col = c("YOUNG","AGED"),
          style = "equal", 
          palette = "Blues") + 
  tm_layout(legend.position = c("right", "bottom")) +
  tm_borders(alpha = 0.5) + 
  tmap_style("white")

```

We can also assign multiple values to aesthetic arguments like *style* and *palette*.

```{r}
tm_shape(mpsz_pop2020)+ 
  tm_polygons(c("DEPENDENCY","AGED"),
              style = c("equal", "quantile"), 
              palette = list("Blues","Greens")) +
  tm_layout(legend.position = c("right", "bottom"))
```

#### 2.4.6.2 By defining a group-by variable in *tm_facets()*

We can create facet maps using *tm_facets()*.

```{r}
tm_shape(mpsz_pop2020) + 
  tm_fill("DEPENDENCY",
          style = "quantile",
          palette = "Blues",
          thres.poly = 0) + 
  tm_facets(by = "REGION_N",
            free.coords = TRUE,
            drop.units  = TRUE) + #instead of drop.shapes as it is deprecated
  tm_layout(legend.show = FALSE,
            title.position = c("center", "center"),
            title.size = 20) + 
  tm_borders(alpha = 0.5)
```

#### 2.4.6.3 By creating multiple stand-alone maps with *tmap_arrange()*

We can create facet maps by creating multiple stand-alone maps and arranging them. In *tmap_arrange(),* arguments *ncol* specifies the number of columns to have and *asp* refers to the aspect ratio of each map.

```{r}
#Create stand-alone maps
youngmap <- tm_shape(mpsz_pop2020)+ 
  tm_polygons("YOUNG", 
              style = "quantile", 
              palette = "Blues")

agedmap <- tm_shape(mpsz_pop2020)+ 
  tm_polygons("AGED", 
              style = "quantile", 
              palette = "Blues")

#Arrange Maps
tmap_arrange(youngmap, agedmap, asp=1, ncol=2) 
```

If there are more than 2 maps, I can just add on for instance:

```{r}
tmap_arrange(youngmap, agedmap, youngmap, agedmap, asp=1.7, ncol=2)
```

### 2.4.7 Mappping Spatial Object Meeting a Selection Criterion

Instead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.

```{r}
tm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N=="CENTRAL REGION", ])+
  tm_fill("DEPENDENCY", 
          style = "quantile", 
          palette = "Blues", 
          legend.hist = TRUE, 
          legend.is.portrait = TRUE,
          legend.hist.z = 0.1) +
  tm_layout(legend.outside = TRUE,
            legend.height = 0.45, 
            legend.width = 5.0,
            legend.position = c("right", "bottom"),
            frame = FALSE) +
  tm_borders(alpha = 0.5)
```
