[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html",
    "title": "Hands-on Exercise 1: Geospatial Data Wranglingand Choropleth Mapping with R",
    "section": "",
    "text": "In the first of this two-part hands-on exercise, I learned how to import, and wrangle geospatial data using appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#data-acquisition",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#data-acquisition",
    "title": "Hands-on Exercise 1: Geospatial Data Wranglingand Choropleth Mapping with R",
    "section": "1.2 Data Acquisition",
    "text": "1.2 Data Acquisition"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#getting-started",
    "title": "Hands-on Exercise 1: Geospatial Data Wranglingand Choropleth Mapping with R",
    "section": "1.3 Getting Started",
    "text": "1.3 Getting Started\nThe code chunk below installs and loads sf and tidyverse packages into R environment. pacman() is a R package management tool. It provides intuitively named functions for the base functions.\n\npacman::p_load(sf, tidyverse)\n\nAn alternate way to install and import the libraries is as follows:\n\npackages = c('sf','tidyverse')\nfor (p in packages){\n  if(!require(p, character.only = T)){\n    install.packages(p)\n  }\n  library(p, character.only = T)\n}"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#import-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#import-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wranglingand Choropleth Mapping with R",
    "section": "1.4 Import Geospatial Data",
    "text": "1.4 Import Geospatial Data\nIn this section, I learned how to import the following geospatial data into R by using st_read() of sf package:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\n1.4.1 Import polygon feature date in shapefile format\nThe code chunk below uses st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a polygon feature data frame.\nWhen the input geospatial data is in shapefile format (.shp), two arguments will be used: dsn to define the data path and layer to provide the shapefile name. No extensions such as .shp, .dbf, .prj and .shx are reqquired.\n\nmpsz = st_read(dsn=\"data\\\\geospatial\",\n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\ameliachuayt\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe output shows that there are 323 multipolygon features and 15 fields. The Bounding box provides the x extend and y extend of the data.\n\n\n1.4.2 Import polyline feature data in shapefile form\nThe code chunk below uses st_read() function of sf package to import CyclingPath shapefile into R as a line feature data frame.\n\ncyclingpath = st_read(dsn = \"data\\\\geospatial\",\n                      layer = 'CyclingPath')\n\nReading layer `CyclingPath' from data source \n  `C:\\ameliachuayt\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1625 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 12711.19 ymin: 28711.33 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\nThe output shows that there are 1625 features and 2 fields in CyclingPath linestring feature data frame and it is in svy21 projected coordinates system.\n\n\n1.4.3 Import GIS data in kml format\nThe code chunk below uses st_read() function of sf package to import pre-schools-location-kml kml file into R as a point feature layer. Since we are dealing with a kml file, instead of specifying dsn and layer, we specify the complete path and file extension.\n\npreschool = st_read(\"data\\\\geospatial\\\\pre-schools-location-kml.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\ameliachuayt\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial\\pre-schools-location-kml.kml' \n  using driver `KML'\nSimple feature collection with 1359 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe output reveals that preschool is a point feature data frame (see “Geometry type: POINT’”). There are a total of 1359 features and 2 fields. Different from the previous two simple feature data frame, preschool is in wgs84 coordinates system (see “Geodetic CRS: WGS 84”)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1: Geospatial Data Wranglingand Choropleth Mapping with R",
    "section": "1.5 Checking the Content of A Simple Feature Data Frame",
    "text": "1.5 Checking the Content of A Simple Feature Data Frame\nIn the section, I learned different ways to retrieve information related to the contents of a simple feature data frame.\n\n1.5.1 Working with st_geometry()\nThe column in the sf data.frame that contains the geometries is a list, of class sfc. We can retrieve the geometry list-column in this case by mpsz$geom or mpsz[[1]], but the more general way uses st_geometry() as shown in the code chunk below.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\nThe output displays basic information of the feature class such as type of geometry, the geographic extent of the features and the coordinate system of the data.\n\n\n1.5.2 Working with glimpse().\nTo learn more about the associated attribute information in the data frame, we can use glimpse() of dplyr.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area <dbl> 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nAs we can see in the output, glimpse() reveals the data type of each field.\nFor example, FMEL-UPD_D is in date data ‘<date>’, and X_ADDR, Y_ADDR are in double precision values ‘<dbl>’\n\n\n1.5.3 Working with head()\nSometimes, we would like to examine complete information of a feature object. We can use head() of Base R to achieve this. The argument n allows us to indicate the number of records to display.\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#plotting-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#plotting-the-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wranglingand Choropleth Mapping with R",
    "section": "1.6 Plotting the Geospatial Data",
    "text": "1.6 Plotting the Geospatial Data\nIn geospatial analytics, we are definitely interested to visualise geospatial features. plot() provides a quick and simply way to visualise the data at hand.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\nThe default plot of sf object is a multi-plot of all attributes, up to a maximum limit (in this case, it is 9 out of 15) as shown above.\nWe can also choose to plot only the geometry by using the code chunk below.\n\nplot(st_geometry(mpsz))\n\n\n\n\nWe can also choose to plot the sf object by using a specific attribute.\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\nAs mentioned earlier, plot() is meant for plotting the geospatial object for quick look. For high cartographic quality plot with more customisation options, tmap or other packages should be used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#working-with-projection",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#working-with-projection",
    "title": "Hands-on Exercise 1: Geospatial Data Wranglingand Choropleth Mapping with R",
    "section": "1.7 Working with Projection",
    "text": "1.7 Working with Projection\nIn order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system. Projection Transformation is the process of projecting a simple feature data frame from one coordinate system to another coordinate system.\n\n1.7.1 Assigning EPSG code to a simple feature data frame\nEPSG stands for European Petroleum Survey Group and is an organisation that maintains a public registry of geodetic parameter database with standard codes–the EPSG codes.\nOne common issue faced during importing geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.\nWe can examine the coordinate system of mpsz simple feature data frame by using st_crs() of sf package as shown in the code chunk below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough the mpsz data frame is projected in ‘svy21’, when we read till the end of the print it indicates that EPSG is 9001, which is wrong. See the last line where “ID[”EPSG”,9001]“.\nThe correct/corresponding EPSG code for ‘svy21’ should be ‘3414’. We can assign the correct EPSG code using st_set_crs() of sf package.\n\nmpsz3414 <- st_set_crs(mpsz, 3414)\n\nWarning: st_crs<- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nTo confirm the change, we can check the coordinate system or CSR again.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNote that the EPSG code is 3414. See last line where “ID[”EPSG”,3414]“.\n\n\n1.7.2 Transforming the projection of preschool from wgs84 to svy21\nIn this sub-section, we will learn how to transform original data from geographic coordinate system to projected coordinate system. We need to do this transformation because the geographic coordinate system is inappropriate if the analysis require the use of distance and/or area measurements.\nFor the preschool simple feature data frame, the output of the code chunk below tells us that it is in the wgs84 coordinate system (see “Geodetic CRS: WGS 85”).\n\nst_geometry(preschool)\n\nGeometry set for 1359 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nPOINT Z (103.7614 1.308683 0)\n\n\nPOINT Z (103.7536 1.315748 0)\n\n\nPOINT Z (103.7645 1.305078 0)\n\n\nPOINT Z (103.765 1.305239 0)\n\n\nPOINT Z (103.7597 1.315983 0)\n\n\nInstead of using st_set_crs() like we did in the previous section, we must use st_transform() of the sf package. This is because we need to reproject preschool from one coordinate system to another coordinate system mathematically.\n\npreschool3414 <- st_transform(preschool,\n                              crs = 3414)\n\n\nNote: In practice, we need to find out the appropriate project coordinate system to use before performing the projection transformation.\n\nLet’s check if the transformation is complete.\n\nst_geometry(preschool3414)\n\nGeometry set for 1359 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11203.01 ymin: 25667.6 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nPOINT Z (19997.26 32333.17 0)\n\n\nPOINT Z (19126.75 33114.35 0)\n\n\nPOINT Z (20345.12 31934.56 0)\n\n\nPOINT Z (20400.31 31952.36 0)\n\n\nPOINT Z (19810.78 33140.31 0)\n\n\nFrom the output, we can see that it is in the svy21 projected coordinate system now (see “Projected CRS: SVY21 / Singapore TM). Also, the Bounding box values are greater than 0-360 range of decimal degree commonly used by most of the geographic coordinate systems."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#importing-and-converting-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#importing-and-converting-aspatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wranglingand Choropleth Mapping with R",
    "section": "1.8 Importing and Converting Aspatial Data",
    "text": "1.8 Importing and Converting Aspatial Data\nIt is common to have data such as listing of inside Airbnb. Such data are called aspatial data. They are not geospatial data, however, among the data fields, there are two fields that capture the x- and y- coordinates of the data points.\nIn this section, I learned to import aspatial data in R environment and save it as a tibbledata frame. Then, I will convert it into a simple feature data frame.\n\n1.8.1 Importing aspatial data\nlistings.csv data set is in csv format and we will use read_csv() or readr package to import the file. The output R object is called listings and is a tibble data frame.\n\nlistings <- read_csv('data\\\\aspatial\\\\listings.csv')\n\nRows: 4252 Columns: 16\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (5): name, host_name, neighbourhood_group, neighbourhood, room_type\ndbl  (10): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nLet’s examine if the import was completely correctly.\n\nlist(listings)\n\n[[1]]\n# A tibble: 4,252 × 16\n       id name     host_id host_…¹ neigh…² neigh…³ latit…⁴ longi…⁵ room_…⁶ price\n    <dbl> <chr>      <dbl> <chr>   <chr>   <chr>     <dbl>   <dbl> <chr>   <dbl>\n 1  50646 Pleasan…  227796 Sujatha Centra… Bukit …    1.33    104. Privat…    80\n 2  71609 Ensuite…  367042 Belinda East R… Tampin…    1.35    104. Privat…   178\n 3  71896 B&B  Ro…  367042 Belinda East R… Tampin…    1.35    104. Privat…    81\n 4  71903 Room 2-…  367042 Belinda East R… Tampin…    1.35    104. Privat…    81\n 5 275343 Conveni… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    52\n 6 275344 15 mins… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    40\n 7 294281 5 mins … 1521514 Elizab… Centra… Newton     1.31    104. Privat…    72\n 8 301247 Nice ro… 1552002 Rahul   Centra… Geylang    1.32    104. Privat…    41\n 9 324945 20 Mins… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    49\n10 330089 Accomo@… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    49\n# … with 4,242 more rows, 6 more variables: minimum_nights <dbl>,\n#   number_of_reviews <dbl>, last_review <date>, reviews_per_month <dbl>,\n#   calculated_host_listings_count <dbl>, availability_365 <dbl>, and\n#   abbreviated variable names ¹​host_name, ²​neighbourhood_group,\n#   ³​neighbourhood, ⁴​latitude, ⁵​longitude, ⁶​room_type\n\n\nThe output reveals that listing tibble data frame consists of 4252 rows and 16 columns. Two useful fields we are going to use in the next phase are latitude and longitude. Note that they are in decimal degree format. As a best guess, we will assume that the data is in wgs84 Geographic Coordinate System\nNote that list() instead of glimpse() was used above. In the code chunk below, we can also print the features of the data using glimpse(). In glimpse(), the columns run down the page and data runs across, enabling us to see all the columns easily.\n\nglimpse(listings)\n\nRows: 4,252\nColumns: 16\n$ id                             <dbl> 50646, 71609, 71896, 71903, 275343, 275…\n$ name                           <chr> \"Pleasant Room along Bukit Timah\", \"Ens…\n$ host_id                        <dbl> 227796, 367042, 367042, 367042, 1439258…\n$ host_name                      <chr> \"Sujatha\", \"Belinda\", \"Belinda\", \"Belin…\n$ neighbourhood_group            <chr> \"Central Region\", \"East Region\", \"East …\n$ neighbourhood                  <chr> \"Bukit Timah\", \"Tampines\", \"Tampines\", …\n$ latitude                       <dbl> 1.33432, 1.34537, 1.34754, 1.34531, 1.2…\n$ longitude                      <dbl> 103.7852, 103.9589, 103.9596, 103.9610,…\n$ room_type                      <chr> \"Private room\", \"Private room\", \"Privat…\n$ price                          <dbl> 80, 178, 81, 81, 52, 40, 72, 41, 49, 49…\n$ minimum_nights                 <dbl> 90, 90, 90, 90, 14, 14, 90, 8, 14, 14, …\n$ number_of_reviews              <dbl> 18, 20, 24, 48, 20, 13, 133, 105, 14, 1…\n$ last_review                    <date> 2014-07-08, 2019-12-28, 2014-12-10, 20…\n$ reviews_per_month              <dbl> 0.22, 0.28, 0.33, 0.67, 0.20, 0.16, 1.2…\n$ calculated_host_listings_count <dbl> 1, 4, 4, 4, 50, 50, 7, 1, 50, 50, 50, 4…\n$ availability_365               <dbl> 365, 365, 365, 365, 353, 364, 365, 90, …\n\n\n\n\n1.8.2 Create simple feature dataframe from aspatial dataframe\nThe code chunk below converts listing data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nlistings_sf <- st_as_sf(listings,\n                        coords = c(\"longitude\",\"latitude\"), #x-coord first, then y-coord\n                        crs=4326) %>% #provide coordinates system in epsg format\n                                      #EPSG:4326 is wgs84\n                                      #EPSG:3414 is Singapore's SVY21 Projected Coordinate System\n  st_transform(crs = 3414)\n\nSeveral things to take note of from the arguments above:\n\ncoords argument requires us to input column name of x-coordinate first, followed by column name of y-coordinate\ncrs argument requires us to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. We can search for other country’s epsg code by referring to epsg.io.\n%>% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\nLet’s examine the content of the newly created simple feature data frame. Note that there is a new column geometry that has been added. Also, the longitude and latitude columns have been dropped.\n\nglimpse(listings_sf)\n\nRows: 4,252\nColumns: 15\n$ id                             <dbl> 50646, 71609, 71896, 71903, 275343, 275…\n$ name                           <chr> \"Pleasant Room along Bukit Timah\", \"Ens…\n$ host_id                        <dbl> 227796, 367042, 367042, 367042, 1439258…\n$ host_name                      <chr> \"Sujatha\", \"Belinda\", \"Belinda\", \"Belin…\n$ neighbourhood_group            <chr> \"Central Region\", \"East Region\", \"East …\n$ neighbourhood                  <chr> \"Bukit Timah\", \"Tampines\", \"Tampines\", …\n$ room_type                      <chr> \"Private room\", \"Private room\", \"Privat…\n$ price                          <dbl> 80, 178, 81, 81, 52, 40, 72, 41, 49, 49…\n$ minimum_nights                 <dbl> 90, 90, 90, 90, 14, 14, 90, 8, 14, 14, …\n$ number_of_reviews              <dbl> 18, 20, 24, 48, 20, 13, 133, 105, 14, 1…\n$ last_review                    <date> 2014-07-08, 2019-12-28, 2014-12-10, 20…\n$ reviews_per_month              <dbl> 0.22, 0.28, 0.33, 0.67, 0.20, 0.16, 1.2…\n$ calculated_host_listings_count <dbl> 1, 4, 4, 4, 50, 50, 7, 1, 50, 50, 50, 4…\n$ availability_365               <dbl> 365, 365, 365, 365, 353, 364, 365, 90, …\n$ geometry                       <POINT [m]> POINT (22646.02 35167.9), POINT (…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#geo-processing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#geo-processing-with-sf-package",
    "title": "Hands-on Exercise 1: Geospatial Data Wranglingand Choropleth Mapping with R",
    "section": "1.9 Geo-processing with sf package",
    "text": "1.9 Geo-processing with sf package\nBesides providing functions to handling (i.e. importing, exporting, assigning projection, transforming projection etc) geospatial data, sf package also offers a wide range of geoprocessing (also known as GIS analysis) functions.\nIn this section, I learned how to perform two commonly used geoprocessing functions:\n\nbuffering and\npoint in polygon count\n\n\n1.9.1 Buffering\nBuffering involves measuring the distance outward in all directions from an object. The output is a polygon.\nTo illustrate how buffering works, how is a hypothetical scenario:\n\n\n\n\n\n\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path.\nTask: Determine the extent of the land that needs to be acquired and their total area.\n\n\n\nSteps to solve:\nStep 1: Compute the 5-meter buffers around the cycling paths\n\nbuffer_cycling <- st_buffer(cyclingpath,\n                            dist = 5, #5 metres\n                            nQuadSegs = 30)\n\nStep 2: Calculate area of buffers\nAs mentioned earlier, the output of buffering is polygons. So here, we can create a new column AREA to store the values of the areas of polygons\n\nbuffer_cycling$AREA <- st_area(buffer_cycling)\n\nStep 3: Derive Total Land Area\nTo do this, we can easily use sum() of Base R\n\nsum(buffer_cycling$AREA)\n\n773143.9 [m^2]\n\n\n\n\n1.9.2 Point-in-polygon Count\nWe can also count the frequency of observations within a polygon. To illustrate this, we have another hypothetical situation\n\n\n\n\n\n\nNote\n\n\n\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nTask: Find out the numbers of pre-schools in each Planning Subzone and the density per square metres.\n\n\nStep 1: Identify pre-schools located in each Subzone and Calculate number of pre-schools in each subzone\nWe can use st_interesects() to identify which subzones pre-schools are located in and lengths() to count the number of pre-schools that fall inside each subzone.\n\nmpsz3414$`PreSch Count` <- lengths(st_intersects(mpsz3414, preschool3414))\n\nCheck descriptive statistics using the below code chunk.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.000   2.000   4.207   6.000  37.000 \n\n\nWe can also list the subzone with the most pre schools using top_n() of dplyr package. We can change the argument within top_n() according to requirements e.g., Top 3, 5, or 10, etc.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 23449.05 ymin: 46001.23 xmax: 25594.22 ymax: 47996.47\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      290          3 WOODLANDS EAST    WDSZ03      N  WOODLANDS         WD\n      REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR\n1 NORTH REGION       NR C90769E43EE6B0F2 2014-12-05 24506.64 46991.63\n  SHAPE_Leng SHAPE_Area                       geometry PreSch Count\n1   6603.608    2553464 MULTIPOLYGON (((24786.75 46...           37\n\n\nStep 2: Derive area of each subzone\nThe code chunk below uses st_area() of sf package to derive the area of each subzone. We are creating a new column Area to store the area values.\n\nmpsz3414$Area <- mpsz3414 %>% \n  st_area()\n\nStep 3: Calculate Density\nWe can simply calculate the density by using mutate() of dplyr package. A new column PreSch Density is created.\n\nmpsz3414 <- mpsz3414 %>%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#exploratory-data-analysis-eda",
    "title": "Hands-on Exercise 1: Geospatial Data Wranglingand Choropleth Mapping with R",
    "section": "1.10 Exploratory Data Analysis (EDA)",
    "text": "1.10 Exploratory Data Analysis (EDA)\nIn this section, I learned appropriate ggplot2 functions to create function yet truthful statistical graphs for EDA purposes.\n\n1.10.1 Distribution of Pre-school Density in Subzones of Singapore using Histograms\nConventionally, hist() of R Graphics can be used to plot a histogram of the distribution of pre-school density. While hist()’s syntax is easy to use, the output does not meet publication quality and it has limited room for customisation.\n\nhist(mpsz3414$`PreSch Density`) \n\n\n\n\nLet’s retry to ggplot2 functions instead.\n\nggplot(data=mpsz3414,\n       aes(x=as.numeric(`PreSch Density`))) +\n  geom_histogram(bins=20,\n                 color=\"black\",\n                 fill = \"light blue\") + \n  labs(title = \"Are pre-schools evenly distributed in Singapore?\",\n       subtitle = \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n       x = \"Pre-school density (per km sq)\",\n       y = \"Frequency\")\n\n\n\n\n\n\n1.10.2 Relationship between Pre-school Density and Pre-school Count using Scatterplot\nDIY: Conventionally, plot() of R Graphics can be used to plot a scatterplot to reveal the relationship between pre-school density and pre-school count.\n\nplot(mpsz3414$`PreSch Density`, mpsz3414$`PreSch Count`, main=\"Pre-school Count vs Pre-school Density\",\n    pch=19)\n\n\n\n\nHowever, we may also opt to use ggplot2 for it has better customisation capabilities.\n\nlibrary(units)\n\nudunits database from C:/R/R-4.2.2/library/units/share/udunits/udunits2.xml\n\nggplot(data=mpsz3414, aes(x=`PreSch Density`, y=`PreSch Count`))+\n  geom_point()+ \n  labs(x = \"Pre-school density (per km sq)\",\n       y = \"Pre-school count\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#overview-of-part-ii",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#overview-of-part-ii",
    "title": "Hands-on Exercise 1: Geospatial Data Wranglingand Choropleth Mapping with R",
    "section": "2.1 Overview Of Part II",
    "text": "2.1 Overview Of Part II\nIn the second of this two-part hands-on exercise, I learned how to plot functional and truthful choropleth maps by using an R package called tmap package.\nChoropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#data-acquisition-1",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#data-acquisition-1",
    "title": "Hands-on Exercise 1: Geospatial Data Wranglingand Choropleth Mapping with R",
    "section": "2.2 Data Acquisition",
    "text": "2.2 Data Acquisition\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#getting-started-importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#getting-started-importing-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wranglingand Choropleth Mapping with R",
    "section": "2.3 Getting Started & Importing Data",
    "text": "2.3 Getting Started & Importing Data"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#getting-started-1",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#getting-started-1",
    "title": "Hands-on Exercise 1: Geospatial Data Wranglingand Choropleth Mapping with R",
    "section": "2.3.1 Getting Started",
    "text": "2.3.1 Getting Started\nThe key R package for this hands-on exercise is tmap package in R. We will also be using four other R packages:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data\n\nThree out of the four are packages (readr, tidyr and dplyr) are part of the tidyverse package. Therefore, we can just load the tidyverse package instead of all three packages.\nThe code chunk below loads sf, tmap and tidyverse packages into R environment.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#importing-geospatial-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#importing-geospatial-data-into-r",
    "title": "Hands-on Exercise 1: Geospatial Data Wranglingand Choropleth Mapping with R",
    "section": "2.3.2 Importing Geospatial Data into R",
    "text": "2.3.2 Importing Geospatial Data into R\nWe can use st_read() of sf package to import MP14_SUBZONE_WEB_PL shapefile in R as a simple feature data frame called mpsz.\n\nmpsz <- st_read(dsn=\"data\\\\geospatial\",\n                layer='MP14_SUBZONE_WEB_PL')\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\ameliachuayt\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nExamine the content of mpsz using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nInterestingly, only the first ten records will be displayed.\nOn the other hand, we can also use head() to specify the number of rows to return (must be less than 10).\n\nhead(mpsz, 3)\n\nSimple feature collection with 3 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 28160.23 ymin: 28369.47 xmax: 32362.39 ymax: 30247.18\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO    SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N PLN_AREA_C\n1        1          1 MARINA SOUTH    MSSZ01      Y    MARINA SOUTH         MS\n2        2          1 PEARL'S HILL    OTSZ01      Y          OUTRAM         OT\n3        3          3    BOAT QUAY    SRSZ03      Y SINGAPORE RIVER         SR\n        REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR\n1 CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84 29220.19\n2 CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06 29782.05\n3 CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96 29974.66\n  SHAPE_Leng SHAPE_Area                       geometry\n1   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n\n\n\n2.3.3 Import Attribute Data\nNext, I imported respopagsex2000to2018.csv file into RStudio and saved the file into an R dataframe called popagsex using read_csv() function of readr package as shown in the code chunk below.\n\npopdata <- read_csv('data\\\\aspatial\\\\respopagesextod2011to2020.csv')\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n2.3.4 Data Preparation\nI am interested to visualise population demographics in the Year 2020. Before a thematic map can be prepared, I need to prepare a data table with Year 2020 values. The following variables will be required for this tasks: PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nPA: Planning Area\nSZ: Planning Subzone\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group.\n\nAs we can see, we will need to wrangle the data set and derive new columns like YOUNG and AGED.\n\n2.3.4.1 Data Wrangling\nThe following data wrangling and transformation functions were used:\n\npivot_wider() of tidyr package, and\n\nthis was used to pivot row values like age to columns. It “widens” data, increasing the number of columns and decreasing the number of rows.\n\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 <- popdata %>%\n  filter(Time == 2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(`POP` = sum(`Pop`)) %>%\n  ungroup()%>%\n  pivot_wider(names_from=AG, \n              values_from=POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %>%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%>%\nmutate(`AGED`=rowSums(.[16:21])) %>%\nmutate(`TOTAL`=rowSums(.[3:21])) %>%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %>%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n2.3.4.2 Joining attribute data and geospatial data\nWe need to convert the PA and SZ values to uppercase.\n\npopdata2020 <- popdata2020 %>%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %>%\n  filter(`ECONOMY ACTIVE` > 0)\n\nWarning: `funs()` was deprecated in dplyr 0.8.0.\nℹ Please use a list of either functions or lambdas:\n\n# Simple named list: list(mean = mean, median = median)\n\n# Auto named with `tibble::lst()`: tibble::lst(mean, median)\n\n# Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\n\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 <- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nWrite the resulting file into a .rds file.\n\nwrite_rds(mpsz_pop2020, \"data\\\\rds\\\\mpszpop2020_amelia.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#choropleth-mapping-geospatial-data-using-tmap-package",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#choropleth-mapping-geospatial-data-using-tmap-package",
    "title": "Hands-on Exercise 1: Geospatial Data Wranglingand Choropleth Mapping with R",
    "section": "2.4 Choropleth Mapping Geospatial Data Using tmap package",
    "text": "2.4 Choropleth Mapping Geospatial Data Using tmap package\nThere are two approaches to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n2.4.1 Plotting choropleth quickly using qtm()\nqtm() of tmap package provides a quick and concise visualisation.\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020,\n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n2.4.2 Creating choropleth map using tmap’s elements\nWhile qtm() can be used to get quick visualisation, the downside is that aesthetics of individual layers are harder to control. To get a high quality cartographic choropleth map, I will use tmap’s drawing elements.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nThe steps to creating the above map will be detailed in this sub-section.\n\n2.4.2.1 Drawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons():\n\ntm_shape() defines the input data\ntm_polygons() draws the planning subzone polygons\n\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n2.4.2.2 Drawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we assign the target variable such as Dependency to tm_polygons().\nBy default, missing values will be shaded in grey.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n2.4.2.3 Drawing a choropleth map using tm_fill() and tm_border()\n\ntm_fill(): shades the polygons using the default colour scheme\ntm_border(): Add borders to the polygons. The arguments are as follows:\n\nalpha specifies the transparency or opaqueness of the borders. By default, the alpha value of the col is used (normally 1 i.e. not transparent). There\ncol specifies the border colour,\nlwd specifies the border line width. The default is 1, and\nlty specifies the border line type. The default is “solid”.\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")+\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n2.4.3 Data classification methods of tmap\nChoropleth maps employ some methods of data classification so to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n2.4.3.1 Plotting choropleth maps with built-in classification methods\nThe code chunk below shows a quantile data classification that used 5 classes (n = 5). This method classifies data into a certain number of categories with an equal number of units in each category.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nIn the code chunk below, equal data classification method is used. This method sets the value ranges in each category equal in size.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nDIY: We can see that the distribution of quantile data classification method are more evenly distributed than equal data classification method.\nLet’s us examine other types of classification methods:\n\nTop Left: pretty (default),\nTop Right: equal,\nBottom Left: jenks and\nBottom Right: kmeans.\n\n\ntm_shape(mpsz_pop2020)+ \n  tm_fill(c(\"DEPENDENCY\",\"DEPENDENCY\",\"DEPENDENCY\",\"DEPENDENCY\"),,\n              style = c(\"pretty\", \"equal\",\"jenks\",\"kmeans\"), \n              palette = list(\"Blues\",\"Oranges\",\"Reds\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))+\n  tm_borders(alpha = 0.2)\n\n\n\n\nWe can observe that pretty and equal gives similar distributions and not as even as the other two. Comparing jenks and kmeans classification methods, we can see that kmeans is more evenly distributed.\nDIY: The below code chunk uses the quantile classification method with different numbers of classes: 2 (top left), 6 (top right), 10 (bottom left), 20 (bottom right).\n\ntm_shape(mpsz_pop2020)+ \n  tm_fill(c(\"DEPENDENCY\",\"DEPENDENCY\",\"DEPENDENCY\",\"DEPENDENCY\"),\n              n = c(2,6,10,20),\n              style = c(\"quantile\", \"quantile\",\"quantile\",\"quantile\"), \n              palette = list(\"Blues\",\"Oranges\",\"Reds\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))+\n  tm_borders(alpha = 0.2)\n\n\n\n\nUnsurprisingly, we can see that as the number of classes increases, the more distributed the data is. Although the differences between the chart diminishes as the number of classes increase–for e.g., classes 10 and 20 are quite similar.\n\n\n\n2.4.3.2 Plotting choropleth map with custom break\nWe can set breakpoints using the breaks argument in tm_fill(). For tmap, breaks include a minimum and maximum. Therefore, to have n categories, n+1 elements must be specified in ascending order.\nFirst, some descriptive stats\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6519  0.7025  0.7742  0.7645 19.0000      92 \n\n\nWith reference to the above, we set break points at 0.00 (min), 0.60, 0.70, 0.80, 0.90, 1.00 (max).\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0.00, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n2.4.4 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package\n\n\n2.4.4.1 Using ColorBrewer Palette\nTo change the colour palette, we assign the preferred colour to palette argument of tm_fill() as shown below.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 6, \n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nWe can reverse the colour shades by adding ‘-’ in the palette argument.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n2.4.5 Map Layouts\nMap layout refers to the combination of all map elements into a cohesive map. Map elements includes: objects to be mapped,title, scale bar, compass, margins and aspects ratios.\n\n2.4.5.1 Map Legend\nIn tmap, legend options allow us to change appearance, position and format of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n2.5.4.2 Map Style\nIn tmap, we can change a wide variety of layout settings using tmap_style(). The classic style is used here. Other available styles are: “white”, “gray”, “natural”, “cobalt”, “col_blind”, “albatross”, “beaver”, “bw”, “watercolor”\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\", \n          palette = \"-Greens\") + \n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n2.4.5.3 Cartographic Furniture\ntmap also provides arguments to draw other map furniture like compass, scale bar and grid lines.\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") + \n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2, \n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) + \n  tm_compass(type=\"8star\", size = 2) + \n  tm_scale_bar(width = 0.15) + \n  tm_grid(lwd = 0.1, alpha = 0.2) + \n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nTo reset to the default style, use the below.\n\ntmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n2.4.6 Drawing Small Multiple Choropleth Maps of Facet Maps\nSmall multiple maps or facet maps are composed of many maps arranged side-by-side or stacked vertically. Using facet maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n2.4.6.1 By assigning multiple values to at least one of the aesthetic arguments\nI created facet maps by defining col in tm_fill().\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(col = c(\"YOUNG\",\"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") + \n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) + \n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\nWe can also assign multiple values to aesthetic arguments like style and palette.\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n              style = c(\"equal\", \"quantile\"), \n              palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n2.4.6.2 By defining a group-by variable in tm_facets()\nWe can create facet maps using tm_facets().\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by = \"REGION_N\",\n            free.coords = TRUE,\n            drop.units  = TRUE) + #instead of drop.shapes as it is deprecated\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"),\n            title.size = 20) + \n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n2.4.6.3 By creating multiple stand-alone maps with tmap_arrange()\nWe can create facet maps by creating multiple stand-alone maps and arranging them. In tmap_arrange(), arguments ncol specifies the number of columns to have and asp refers to the aspect ratio of each map.\n\n#Create stand-alone maps\nyoungmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\n#Arrange Maps\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2) \n\n\n\n\nIf there are more than 2 maps, I can just add on for instance:\n\ntmap_arrange(youngmap, agedmap, youngmap, agedmap, asp=1.7, ncol=2)\n\n\n\n\n\n\n\n2.4.7 Mappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#references",
    "title": "Hands-on Exercise 1: Geospatial Data Wranglingand Choropleth Mapping with R",
    "section": "3 References",
    "text": "3 References\n\nR for Geospatial Data Science and Analytics - Chapter 1: Geospatial Data Wrangling with R\nR for Geospatial Data Science and Analytics - Chapter 2: Choropleth Mapping with R"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS624",
    "section": "",
    "text": "In this webpage, I am going to share with you my learning journey of geospatial analytics."
  }
]