[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html",
    "href": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "",
    "text": "There are two parts in this hands-on exercise:"
  },
  {
    "objectID": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#data-acquisition",
    "href": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#data-acquisition",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "1.2 Data Acquisition",
    "text": "1.2 Data Acquisition\nData are key to data analytics including geospatial analytics. Hence, before analysing, we need to assemble the necessary data. For this hands-on exercise, data sets were extracted from the following sources:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb"
  },
  {
    "objectID": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#getting-started",
    "href": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#getting-started",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "1.3 Getting Started",
    "text": "1.3 Getting Started\nThe code chunk below installs and loads sf and tidyverse packages into R environment. pacman() is a R package management tool. It provides intuitively named functions for the base functions.\n\npacman::p_load(sf, tidyverse)\n\nAn alternate way to install and import the libraries is as follows:\n\npackages = c('sf','tidyverse')\nfor (p in packages){\n  if(!require(p, character.only = T)){\n    install.packages(p)\n  }\n  library(p, character.only = T)\n}"
  },
  {
    "objectID": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#import-geospatial-data",
    "href": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#import-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "1.4 Import Geospatial Data",
    "text": "1.4 Import Geospatial Data\nIn this section, I learned how to import the following geospatial data into R by using st_read() of sf package:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\n1.4.1 Import polygon feature date in shapefile format\nThe code chunk below uses st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a polygon feature data frame.\nWhen the input geospatial data is in shapefile format (.shp), two arguments will be used: dsn to define the data path and layer to provide the shapefile name. No extensions such as .shp, .dbf, .prj and .shx are reqquired.\n\nmpsz = st_read(dsn=\"data\\\\geospatial\",\n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\ameliachuayt\\ISSS624\\Exercises\\Hands-on_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe output shows that there are 323 multipolygon features and 15 fields. The Bounding box provides the x extend and y extend of the data.\n\n\n1.4.2 Import polyline feature data in shapefile form\nThe code chunk below uses st_read() function of sf package to import CyclingPath shapefile into R as a line feature data frame.\n\ncyclingpath = st_read(dsn = \"data\\\\geospatial\",\n                      layer = 'CyclingPath')\n\nReading layer `CyclingPath' from data source \n  `C:\\ameliachuayt\\ISSS624\\Exercises\\Hands-on_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1625 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 12711.19 ymin: 28711.33 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\nThe output shows that there are 1625 features and 2 fields in CyclingPath linestring feature data frame and it is in svy21 projected coordinates system.\n\n\n1.4.3 Import GIS data in kml format\nThe code chunk below uses st_read() function of sf package to import pre-schools-location-kml kml file into R as a point feature layer. Since we are dealing with a kml file, instead of specifying dsn and layer, we specify the complete path and file extension.\n\npreschool = st_read(\"data\\\\geospatial\\\\pre-schools-location-kml.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\ameliachuayt\\ISSS624\\Exercises\\Hands-on_Ex1\\data\\geospatial\\pre-schools-location-kml.kml' \n  using driver `KML'\nSimple feature collection with 1359 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe output reveals that preschool is a point feature data frame (see “Geometry type: POINT’”). There are a total of 1359 features and 2 fields. Different from the previous two simple feature data frame, preschool is in wgs84 coordinates system (see “Geodetic CRS: WGS 84”)."
  },
  {
    "objectID": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "1.5 Checking the Content of A Simple Feature Data Frame",
    "text": "1.5 Checking the Content of A Simple Feature Data Frame\nIn the section, I learned different ways to retrieve information related to the contents of a simple feature data frame.\n\n1.5.1 Working with st_geometry()\nThe column in the sf data.frame that contains the geometries is a list, of class sfc. We can retrieve the geometry list-column in this case by mpsz$geom or mpsz[[1]], but the more general way uses st_geometry() as shown in the code chunk below.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\nThe output displays basic information of the feature class such as type of geometry, the geographic extent of the features and the coordinate system of the data.\n\n\n1.5.2 Working with glimpse().\nTo learn more about the associated attribute information in the data frame, we can use glimpse() of dplyr.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area <dbl> 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nAs we can see in the output, glimpse() reveals the data type of each field.\nFor example, FMEL-UPD_D is in date data ‘<date>’, and X_ADDR, Y_ADDR are in double precision values ‘<dbl>’\n\n\n1.5.3 Working with head()\nSometimes, we would like to examine complete information of a feature object. We can use head() of Base R to achieve this. The argument n allows us to indicate the number of records to display.\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#plotting-the-geospatial-data",
    "href": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#plotting-the-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "1.6 Plotting the Geospatial Data",
    "text": "1.6 Plotting the Geospatial Data\nIn geospatial analytics, we are definitely interested to visualise geospatial features. plot() provides a quick and simply way to visualise the data at hand.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\nThe default plot of sf object is a multi-plot of all attributes, up to a maximum limit (in this case, it is 9 out of 15) as shown above.\nWe can also choose to plot only the geometry by using the code chunk below.\n\nplot(st_geometry(mpsz))\n\n\n\n\nWe can also choose to plot the sf object by using a specific attribute.\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\nAs mentioned earlier, plot() is meant for plotting the geospatial object for quick look. For high cartographic quality plot with more customisation options, tmap or other packages should be used."
  },
  {
    "objectID": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#working-with-projection",
    "href": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#working-with-projection",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "1.7 Working with Projection",
    "text": "1.7 Working with Projection\nIn order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system. Projection Transformation is the process of projecting a simple feature data frame from one coordinate system to another coordinate system.\n\n1.7.1 Assigning EPSG code to a simple feature data frame\nEPSG stands for European Petroleum Survey Group and is an organisation that maintains a public registry of geodetic parameter database with standard codes–the EPSG codes.\nOne common issue faced during importing geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.\nWe can examine the coordinate system of mpsz simple feature data frame by using st_crs() of sf package as shown in the code chunk below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough the mpsz data frame is projected in ‘svy21’, when we read till the end of the print it indicates that EPSG is 9001, which is wrong. See the last line where “ID[”EPSG”,9001]“.\nThe correct/corresponding EPSG code for ‘svy21’ should be ‘3414’. We can assign the correct EPSG code using st_set_crs() of sf package.\n\nmpsz3414 <- st_set_crs(mpsz, 3414)\n\nWarning: st_crs<- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nTo confirm the change, we can check the coordinate system or CSR again.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNote that the EPSG code is 3414. See last line where “ID[”EPSG”,3414]“.\n\n\n1.7.2 Transforming the projection of preschool from wgs84 to svy21\nIn this sub-section, we will learn how to transform original data from geographic coordinate system to projected coordinate system. We need to do this transformation because the geographic coordinate system is inappropriate if the analysis require the use of distance and/or area measurements.\nFor the preschool simple feature data frame, the output of the code chunk below tells us that it is in the wgs84 coordinate system (see “Geodetic CRS: WGS 85”).\n\nst_geometry(preschool)\n\nGeometry set for 1359 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nPOINT Z (103.7614 1.308683 0)\n\n\nPOINT Z (103.7536 1.315748 0)\n\n\nPOINT Z (103.7645 1.305078 0)\n\n\nPOINT Z (103.765 1.305239 0)\n\n\nPOINT Z (103.7597 1.315983 0)\n\n\nInstead of using st_set_crs() like we did in the previous section, we must use st_transform() of the sf package. This is because we need to reproject preschool from one coordinate system to another coordinate system mathematically.\n\npreschool3414 <- st_transform(preschool,\n                              crs = 3414)\n\n\nNote: In practice, we need to find out the appropriate project coordinate system to use before performing the projection transformation.\n\nLet’s check if the transformation is complete.\n\nst_geometry(preschool3414)\n\nGeometry set for 1359 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11203.01 ymin: 25667.6 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nPOINT Z (19997.26 32333.17 0)\n\n\nPOINT Z (19126.75 33114.35 0)\n\n\nPOINT Z (20345.12 31934.56 0)\n\n\nPOINT Z (20400.31 31952.36 0)\n\n\nPOINT Z (19810.78 33140.31 0)\n\n\nFrom the output, we can see that it is in the svy21 projected coordinate system now (see “Projected CRS: SVY21 / Singapore TM). Also, the Bounding box values are greater than 0-360 range of decimal degree commonly used by most of the geographic coordinate systems.\nAlternatively, the code chunk below will import and transform GIS data into projected coordinates system data. (Instead of importing and transforming in two separate code chunks.)\n\npreschool = st_read(\"data\\\\geospatial\\\\pre-schools-location-kml.kml\") %>%\n  st_transform(crs = 3414)\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\ameliachuayt\\ISSS624\\Exercises\\Hands-on_Ex1\\data\\geospatial\\pre-schools-location-kml.kml' \n  using driver `KML'\nSimple feature collection with 1359 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nWhile the results states that Geodetic CRS is WGS84, we can examine the dataframe and see that under geometry , the coordinates are no longer in wgs84 (the values are larger than 360)."
  },
  {
    "objectID": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#importing-and-converting-aspatial-data",
    "href": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#importing-and-converting-aspatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "1.8 Importing and Converting Aspatial Data",
    "text": "1.8 Importing and Converting Aspatial Data\nIt is common to have data such as listing of inside Airbnb. Such data are called aspatial data. They are not geospatial data, however, among the data fields, there are two fields that capture the x- and y- coordinates of the data points.\nIn this section, I learned to import aspatial data in R environment and save it as a tibbledata frame. Then, I will convert it into a simple feature data frame.\n\n1.8.1 Importing aspatial data\nlistings.csv data set is in csv format and we will use read_csv() of readr package to import the file. The output R object is called listings and is a tibble data frame.\n\nlistings <- read_csv('data\\\\aspatial\\\\listings.csv')\n\nRows: 4252 Columns: 16\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (5): name, host_name, neighbourhood_group, neighbourhood, room_type\ndbl  (10): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nLet’s examine if the import was completely correctly.\n\nlist(listings)\n\n[[1]]\n# A tibble: 4,252 × 16\n       id name     host_id host_…¹ neigh…² neigh…³ latit…⁴ longi…⁵ room_…⁶ price\n    <dbl> <chr>      <dbl> <chr>   <chr>   <chr>     <dbl>   <dbl> <chr>   <dbl>\n 1  50646 Pleasan…  227796 Sujatha Centra… Bukit …    1.33    104. Privat…    80\n 2  71609 Ensuite…  367042 Belinda East R… Tampin…    1.35    104. Privat…   178\n 3  71896 B&B  Ro…  367042 Belinda East R… Tampin…    1.35    104. Privat…    81\n 4  71903 Room 2-…  367042 Belinda East R… Tampin…    1.35    104. Privat…    81\n 5 275343 Conveni… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    52\n 6 275344 15 mins… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    40\n 7 294281 5 mins … 1521514 Elizab… Centra… Newton     1.31    104. Privat…    72\n 8 301247 Nice ro… 1552002 Rahul   Centra… Geylang    1.32    104. Privat…    41\n 9 324945 20 Mins… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    49\n10 330089 Accomo@… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    49\n# … with 4,242 more rows, 6 more variables: minimum_nights <dbl>,\n#   number_of_reviews <dbl>, last_review <date>, reviews_per_month <dbl>,\n#   calculated_host_listings_count <dbl>, availability_365 <dbl>, and\n#   abbreviated variable names ¹​host_name, ²​neighbourhood_group,\n#   ³​neighbourhood, ⁴​latitude, ⁵​longitude, ⁶​room_type\n\n\nThe output reveals that listing tibble data frame consists of 4252 rows and 16 columns. Two useful fields we are going to use in the next phase are latitude and longitude. Note that they are in decimal degree format. As a best guess, we will assume that the data is in wgs84 Geographic Coordinate System\nNote that list() instead of glimpse() was used above. In the code chunk below, we can also print the features of the data using glimpse(). In glimpse(), the columns run down the page and data runs across, enabling us to see all the columns easily.\n\nglimpse(listings)\n\nRows: 4,252\nColumns: 16\n$ id                             <dbl> 50646, 71609, 71896, 71903, 275343, 275…\n$ name                           <chr> \"Pleasant Room along Bukit Timah\", \"Ens…\n$ host_id                        <dbl> 227796, 367042, 367042, 367042, 1439258…\n$ host_name                      <chr> \"Sujatha\", \"Belinda\", \"Belinda\", \"Belin…\n$ neighbourhood_group            <chr> \"Central Region\", \"East Region\", \"East …\n$ neighbourhood                  <chr> \"Bukit Timah\", \"Tampines\", \"Tampines\", …\n$ latitude                       <dbl> 1.33432, 1.34537, 1.34754, 1.34531, 1.2…\n$ longitude                      <dbl> 103.7852, 103.9589, 103.9596, 103.9610,…\n$ room_type                      <chr> \"Private room\", \"Private room\", \"Privat…\n$ price                          <dbl> 80, 178, 81, 81, 52, 40, 72, 41, 49, 49…\n$ minimum_nights                 <dbl> 90, 90, 90, 90, 14, 14, 90, 8, 14, 14, …\n$ number_of_reviews              <dbl> 18, 20, 24, 48, 20, 13, 133, 105, 14, 1…\n$ last_review                    <date> 2014-07-08, 2019-12-28, 2014-12-10, 20…\n$ reviews_per_month              <dbl> 0.22, 0.28, 0.33, 0.67, 0.20, 0.16, 1.2…\n$ calculated_host_listings_count <dbl> 1, 4, 4, 4, 50, 50, 7, 1, 50, 50, 50, 4…\n$ availability_365               <dbl> 365, 365, 365, 365, 353, 364, 365, 90, …\n\n\n\n\n1.8.2 Create simple feature dataframe from aspatial dataframe\nThe code chunk below converts listing data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nlistings_sf <- st_as_sf(listings,\n                        coords = c(\"longitude\",\"latitude\"), #x-coord first, then y-coord\n                        crs=4326) %>% #provide coordinates system in epsg format\n                                      #EPSG:4326 is wgs84\n                                      #EPSG:3414 is Singapore's SVY21 Projected Coordinate System\n  st_transform(crs = 3414)\n\nSeveral things to take note of from the arguments above:\n\ncoords argument requires us to input column name of x-coordinate first, followed by column name of y-coordinate\ncrs argument requires us to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. We can search for other country’s epsg code by referring to epsg.io.\n%>% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\nLet’s examine the content of the newly created simple feature data frame. Note that there is a new column geometry that has been added. Also, the longitude and latitude columns have been dropped.\n\nglimpse(listings_sf)\n\nRows: 4,252\nColumns: 15\n$ id                             <dbl> 50646, 71609, 71896, 71903, 275343, 275…\n$ name                           <chr> \"Pleasant Room along Bukit Timah\", \"Ens…\n$ host_id                        <dbl> 227796, 367042, 367042, 367042, 1439258…\n$ host_name                      <chr> \"Sujatha\", \"Belinda\", \"Belinda\", \"Belin…\n$ neighbourhood_group            <chr> \"Central Region\", \"East Region\", \"East …\n$ neighbourhood                  <chr> \"Bukit Timah\", \"Tampines\", \"Tampines\", …\n$ room_type                      <chr> \"Private room\", \"Private room\", \"Privat…\n$ price                          <dbl> 80, 178, 81, 81, 52, 40, 72, 41, 49, 49…\n$ minimum_nights                 <dbl> 90, 90, 90, 90, 14, 14, 90, 8, 14, 14, …\n$ number_of_reviews              <dbl> 18, 20, 24, 48, 20, 13, 133, 105, 14, 1…\n$ last_review                    <date> 2014-07-08, 2019-12-28, 2014-12-10, 20…\n$ reviews_per_month              <dbl> 0.22, 0.28, 0.33, 0.67, 0.20, 0.16, 1.2…\n$ calculated_host_listings_count <dbl> 1, 4, 4, 4, 50, 50, 7, 1, 50, 50, 50, 4…\n$ availability_365               <dbl> 365, 365, 365, 365, 353, 364, 365, 90, …\n$ geometry                       <POINT [m]> POINT (22646.02 35167.9), POINT (…"
  },
  {
    "objectID": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#geo-processing-with-sf-package",
    "href": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#geo-processing-with-sf-package",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "1.9 Geo-processing with sf package",
    "text": "1.9 Geo-processing with sf package\nBesides providing functions to handling (i.e. importing, exporting, assigning projection, transforming projection etc) geospatial data, sf package also offers a wide range of geoprocessing (also known as GIS analysis) functions.\nIn this section, I learned how to perform two commonly used geoprocessing functions:\n\nbuffering and\npoint in polygon count\n\n\n1.9.1 Buffering\nBuffering involves measuring the distance outward in all directions from an object. The output is a polygon.\nTo illustrate how buffering works, how is a hypothetical scenario:\n\n\n\n\n\n\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path.\nTask: Determine the extent of the land that needs to be acquired and their total area.\n\n\n\nSteps to solve:\nStep 1: Compute the 5-meter buffers around the cycling paths\n\nbuffer_cycling <- st_buffer(cyclingpath,\n                            dist = 5, #5 metres\n                            nQuadSegs = 30)\n\nStep 2: Calculate area of buffers\nAs mentioned earlier, the output of buffering is polygons. So here, we can create a new column AREA to store the values of the areas of polygons\n\nbuffer_cycling$AREA <- st_area(buffer_cycling)\n\nStep 3: Derive Total Land Area\nTo do this, we can easily use sum() of Base R\n\nsum(buffer_cycling$AREA)\n\n773143.9 [m^2]\n\n\n\n\n1.9.2 Point-in-polygon Count\nWe can also count the frequency of observations within a polygon. To illustrate this, we have another hypothetical situation\n\n\n\n\n\n\nNote\n\n\n\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nTask: Find out the numbers of pre-schools in each Planning Subzone and the density per square metres.\n\n\nStep 1: Identify pre-schools located in each Subzone and Calculate number of pre-schools in each subzone\nWe can use st_interesects() to identify which subzones pre-schools are located in and lengths() to count the number of pre-schools that fall inside each subzone.\n\nmpsz3414$`PreSch Count` <- lengths(st_intersects(mpsz3414, preschool3414))\n\nCheck descriptive statistics using the below code chunk.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.000   2.000   4.207   6.000  37.000 \n\n\nWe can also list the subzone with the most pre schools using top_n() of dplyr package. We can change the argument within top_n() according to requirements e.g., Top 3, 5, or 10, etc.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 23449.05 ymin: 46001.23 xmax: 25594.22 ymax: 47996.47\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      290          3 WOODLANDS EAST    WDSZ03      N  WOODLANDS         WD\n      REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR\n1 NORTH REGION       NR C90769E43EE6B0F2 2014-12-05 24506.64 46991.63\n  SHAPE_Leng SHAPE_Area                       geometry PreSch Count\n1   6603.608    2553464 MULTIPOLYGON (((24786.75 46...           37\n\n\nStep 2: Derive area of each subzone\nThe code chunk below uses st_area() of sf package to derive the area of each subzone. We are creating a new column Area to store the area values.\n\nmpsz3414$Area <- mpsz3414 %>% \n  st_area()\n\nStep 3: Calculate Density\nWe can simply calculate the density by using mutate() of dplyr package. A new column PreSch Density is created.\n\nmpsz3414 <- mpsz3414 %>%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#exploratory-data-analysis-eda",
    "href": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#exploratory-data-analysis-eda",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "1.10 Exploratory Data Analysis (EDA)",
    "text": "1.10 Exploratory Data Analysis (EDA)\nIn this section, I learned appropriate ggplot2 functions to create function yet truthful statistical graphs for EDA purposes.\n\n1.10.0.1 Distribution of Pre-school Density in Subzones of Singapore using Histograms\nConventionally, hist() of R Graphics can be used to plot a histogram of the distribution of pre-school density. While hist()’s syntax is easy to use, the output does not meet publication quality and it has limited room for customisation.\n\nhist(mpsz3414$`PreSch Density`) \n\n\n\n\nLet’s retry to ggplot2 functions instead.\n\nggplot(data=mpsz3414,\n       aes(x=as.numeric(`PreSch Density`))) +\n  geom_histogram(bins=20,\n                 color=\"black\",\n                 fill = \"light blue\") + \n  labs(title = \"Are pre-schools evenly distributed in Singapore?\",\n       subtitle = \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n       x = \"Pre-school density (per km sq)\",\n       y = \"Frequency\")\n\n\n\n\n\n\n1.10.0.2 Relationship between Pre-school Density and Pre-school Count using Scatterplot\nDIY: Conventionally, plot() of R Graphics can be used to plot a scatterplot to reveal the relationship between pre-school density and pre-school count.\n\nplot(mpsz3414$`PreSch Density`, mpsz3414$`PreSch Count`, main=\"Pre-school Count vs Pre-school Density\",\n    pch=19)\n\n\n\n\nHowever, we may also opt to use ggplot2 for it has better customisation capabilities.\n\nlibrary(units)\n\nudunits database from C:/R/R-4.2.2/library/units/share/udunits/udunits2.xml\n\nggplot(data=mpsz3414, aes(x=`PreSch Density`, y=`PreSch Count`))+\n  geom_point()+ \n  labs(x = \"Pre-school density (per km sq)\",\n       y = \"Pre-school count\")"
  },
  {
    "objectID": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#overview-of-part-ii",
    "href": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#overview-of-part-ii",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "2.1 Overview Of Part II",
    "text": "2.1 Overview Of Part II\nIn the second of this two-part hands-on exercise, I learned how to plot functional and truthful choropleth maps by using an R package called tmap package.\nChoropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary."
  },
  {
    "objectID": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#data-acquisition-1",
    "href": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#data-acquisition-1",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "2.2 Data Acquisition",
    "text": "2.2 Data Acquisition\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile."
  },
  {
    "objectID": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#getting-started-importing-data",
    "href": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#getting-started-importing-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "2.3 Getting Started & Importing Data",
    "text": "2.3 Getting Started & Importing Data"
  },
  {
    "objectID": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#getting-started-1",
    "href": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#getting-started-1",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "2.4 Getting Started",
    "text": "2.4 Getting Started\nThe key R package for this hands-on exercise is tmap package in R. We will also be using four other R packages:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data\n\nThree out of the four are packages (readr, tidyr and dplyr) are part of the tidyverse package. Therefore, we can just load the tidyverse package instead of all three packages.\nThe code chunk below loads sf, tmap and tidyverse packages into R environment.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n2.4.1 Importing Geospatial Data into R\nWe can use st_read() of sf package to import MP14_SUBZONE_WEB_PL shapefile in R as a simple feature data frame called mpsz.\n\nmpsz <- st_read(dsn=\"data\\\\geospatial\",\n                layer='MP14_SUBZONE_WEB_PL')\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\ameliachuayt\\ISSS624\\Exercises\\Hands-on_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nExamine the content of mpsz using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nInterestingly, only the first ten records will be displayed.\nOn the other hand, we can also use head() to specify the number of rows to return (must be less than 10).\n\nhead(mpsz, 3)\n\nSimple feature collection with 3 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 28160.23 ymin: 28369.47 xmax: 32362.39 ymax: 30247.18\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO    SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N PLN_AREA_C\n1        1          1 MARINA SOUTH    MSSZ01      Y    MARINA SOUTH         MS\n2        2          1 PEARL'S HILL    OTSZ01      Y          OUTRAM         OT\n3        3          3    BOAT QUAY    SRSZ03      Y SINGAPORE RIVER         SR\n        REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR\n1 CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84 29220.19\n2 CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06 29782.05\n3 CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96 29974.66\n  SHAPE_Leng SHAPE_Area                       geometry\n1   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n\n\n\n\n2.4.2 Import Attribute Data\nNext, I imported respopagsex2000to2018.csv file into RStudio and saved the file into an R dataframe called popagsex using read_csv() function of readr package as shown in the code chunk below.\n\npopdata <- read_csv('data\\\\aspatial\\\\respopagesextod2011to2020.csv')\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n2.4.3 Data Preparation\nI am interested to visualise population demographics in the Year 2020. Before a thematic map can be prepared, I need to prepare a data table with Year 2020 values. The following variables will be required for this tasks: PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nPA: Planning Area\nSZ: Planning Subzone\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group.\n\nAs we can see, we will need to wrangle the data set and derive new columns like YOUNG and AGED.\n\n2.4.3.1 Data Wrangling\nThe following data wrangling and transformation functions were used:\n\npivot_wider() of tidyr package, and\n\nthis was used to pivot row values like age to columns. It “widens” data, increasing the number of columns and decreasing the number of rows.\n\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 <- popdata %>%\n  filter(Time == 2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(`POP` = sum(`Pop`)) %>%\n  ungroup()%>%\n  pivot_wider(names_from=AG, \n              values_from=POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %>%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%>%\nmutate(`AGED`=rowSums(.[16:21])) %>%\nmutate(`TOTAL`=rowSums(.[3:21])) %>%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %>%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n2.4.3.2 Joining attribute data and geospatial data\nWe need to convert the PA and SZ values to uppercase.\n\npopdata2020 <- popdata2020 %>%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %>%\n  filter(`ECONOMY ACTIVE` > 0)\n\nWarning: `funs()` was deprecated in dplyr 0.8.0.\nℹ Please use a list of either functions or lambdas:\n\n# Simple named list: list(mean = mean, median = median)\n\n# Auto named with `tibble::lst()`: tibble::lst(mean, median)\n\n# Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\n\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 <- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nWrite the resulting file into a .rds file.\n\nwrite_rds(mpsz_pop2020, \"data\\\\rds\\\\mpszpop2020_amelia.rds\")"
  },
  {
    "objectID": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#importing-geospatial-data-into-r",
    "href": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#importing-geospatial-data-into-r",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "2.3.2 Importing Geospatial Data into R",
    "text": "2.3.2 Importing Geospatial Data into R\nWe can use st_read() of sf package to import MP14_SUBZONE_WEB_PL shapefile in R as a simple feature data frame called mpsz.\n\nmpsz <- st_read(dsn=\"data\\\\geospatial\",\n                layer='MP14_SUBZONE_WEB_PL')\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\ameliachuayt\\ISSS624\\Exercises\\Hands-on_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nExamine the content of mpsz using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nInterestingly, only the first ten records will be displayed.\nOn the other hand, we can also use head() to specify the number of rows to return (must be less than 10).\n\nhead(mpsz, 3)\n\nSimple feature collection with 3 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 28160.23 ymin: 28369.47 xmax: 32362.39 ymax: 30247.18\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO    SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N PLN_AREA_C\n1        1          1 MARINA SOUTH    MSSZ01      Y    MARINA SOUTH         MS\n2        2          1 PEARL'S HILL    OTSZ01      Y          OUTRAM         OT\n3        3          3    BOAT QUAY    SRSZ03      Y SINGAPORE RIVER         SR\n        REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR\n1 CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84 29220.19\n2 CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06 29782.05\n3 CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96 29974.66\n  SHAPE_Leng SHAPE_Area                       geometry\n1   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n\n\n\n2.3.3 Import Attribute Data\nNext, I imported respopagsex2000to2018.csv file into RStudio and saved the file into an R dataframe called popagsex using read_csv() function of readr package as shown in the code chunk below.\n\npopdata <- read_csv('data\\\\aspatial\\\\respopagesextod2011to2020.csv')\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n2.3.4 Data Preparation\nI am interested to visualise population demographics in the Year 2020. Before a thematic map can be prepared, I need to prepare a data table with Year 2020 values. The following variables will be required for this tasks: PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nPA: Planning Area\nSZ: Planning Subzone\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group.\n\nAs we can see, we will need to wrangle the data set and derive new columns like YOUNG and AGED.\n\n2.3.4.1 Data Wrangling\nThe following data wrangling and transformation functions were used:\n\npivot_wider() of tidyr package, and\n\nthis was used to pivot row values like age to columns. It “widens” data, increasing the number of columns and decreasing the number of rows.\n\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 <- popdata %>%\n  filter(Time == 2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(`POP` = sum(`Pop`)) %>%\n  ungroup()%>%\n  pivot_wider(names_from=AG, \n              values_from=POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %>%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%>%\nmutate(`AGED`=rowSums(.[16:21])) %>%\nmutate(`TOTAL`=rowSums(.[3:21])) %>%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %>%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n2.3.4.2 Joining attribute data and geospatial data\nWe need to convert the PA and SZ values to uppercase.\n\npopdata2020 <- popdata2020 %>%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %>%\n  filter(`ECONOMY ACTIVE` > 0)\n\nWarning: `funs()` was deprecated in dplyr 0.8.0.\nℹ Please use a list of either functions or lambdas:\n\n# Simple named list: list(mean = mean, median = median)\n\n# Auto named with `tibble::lst()`: tibble::lst(mean, median)\n\n# Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\n\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 <- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nWrite the resulting file into a .rds file.\n\nwrite_rds(mpsz_pop2020, \"data\\\\rds\\\\mpszpop2020_amelia.rds\")"
  },
  {
    "objectID": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#choropleth-mapping-geospatial-data-using-tmap-package",
    "href": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#choropleth-mapping-geospatial-data-using-tmap-package",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "2.5 Choropleth Mapping Geospatial Data Using tmap package",
    "text": "2.5 Choropleth Mapping Geospatial Data Using tmap package\nThere are two approaches to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n2.5.1 Plotting choropleth quickly using qtm()\nqtm() of tmap package provides a quick and concise visualisation.\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020,\n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n2.5.2 Creating choropleth map using tmap’s elements\nWhile qtm() can be used to get quick visualisation, the downside is that aesthetics of individual layers are harder to control. To get a high quality cartographic choropleth map, I will use tmap’s drawing elements.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nThe steps to creating the above map will be detailed in this sub-section.\n\n2.5.2.1 Drawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons():\n\ntm_shape() defines the input data\ntm_polygons() draws the planning subzone polygons\n\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n2.5.2.2 Drawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we assign the target variable such as Dependency to tm_polygons().\nBy default, missing values will be shaded in grey.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n2.5.2.3 Drawing a choropleth map using tm_fill() and tm_border()\n\ntm_fill(): shades the polygons using the default colour scheme\ntm_border(): Add borders to the polygons. The arguments are as follows:\n\nalpha specifies the transparency or opaqueness of the borders. By default, the alpha value of the col is used (normally 1 i.e. not transparent). There\ncol specifies the border colour,\nlwd specifies the border line width. The default is 1, and\nlty specifies the border line type. The default is “solid”.\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")+\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n2.5.3 Data classification methods of tmap\nChoropleth maps employ some methods of data classification so to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n2.5.3.1 Plotting choropleth maps with built-in classification methods\nThe code chunk below shows a quantile data classification that used 5 classes (n = 5). This method classifies data into a certain number of categories with an equal number of units in each category.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nIn the code chunk below, equal data classification method is used. This method sets the value ranges in each category equal in size.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nDIY: We can see that the distribution of quantile data classification method are more evenly distributed than equal data classification method.\nLet’s us examine other types of classification methods:\n\nTop Left: pretty (default),\nTop Right: equal,\nBottom Left: jenks and\nBottom Right: kmeans.\n\n\ntm_shape(mpsz_pop2020)+ \n  tm_fill(c(\"DEPENDENCY\",\"DEPENDENCY\",\"DEPENDENCY\",\"DEPENDENCY\"),,\n              style = c(\"pretty\", \"equal\",\"jenks\",\"kmeans\"), \n              palette = list(\"Blues\",\"Oranges\",\"Reds\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))+\n  tm_borders(alpha = 0.2)\n\n\n\n\nWe can observe that pretty and equal gives similar distributions and not as even as the other two. Comparing jenks and kmeans classification methods, we can see that kmeans is more evenly distributed.\nDIY: The below code chunk uses the quantile classification method with different numbers of classes: 2 (top left), 6 (top right), 10 (bottom left), 20 (bottom right).\n\ntm_shape(mpsz_pop2020)+ \n  tm_fill(c(\"DEPENDENCY\",\"DEPENDENCY\",\"DEPENDENCY\",\"DEPENDENCY\"),\n              n = c(2,6,10,20),\n              style = c(\"quantile\", \"quantile\",\"quantile\",\"quantile\"), \n              palette = list(\"Blues\",\"Oranges\",\"Reds\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))+\n  tm_borders(alpha = 0.2)\n\n\n\n\nUnsurprisingly, we can see that as the number of classes increases, the more distributed the data is. Although the differences between the chart diminishes as the number of classes increase–for e.g., classes 10 and 20 are quite similar.\n\n\n2.5.3.2 \n2.4.3.2 Plotting choropleth map with custom break\nWe can set breakpoints using the breaks argument in tm_fill(). For tmap, breaks include a minimum and maximum. Therefore, to have n categories, n+1 elements must be specified in ascending order.\nFirst, some descriptive stats\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6519  0.7025  0.7742  0.7645 19.0000      92 \n\n\nWith reference to the above, we set break points at 0.00 (min), 0.60, 0.70, 0.80, 0.90, 1.00 (max).\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0.00, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n\n\n\n2.5.4 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package\n\n2.5.4.1 Using ColorBrewer Palette\nTo change the colour palette, we assign the preferred colour to palette argument of tm_fill() as shown below.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 6, \n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nWe can reverse the colour shades by adding ‘-’ in the palette argument.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n2.5.5 Map Layouts\nMap layout refers to the combination of all map elements into a cohesive map. Map elements includes: objects to be mapped,title, scale bar, compass, margins and aspects ratios.\n\n2.5.5.1 Map Legend\nIn tmap, legend options allow us to change appearance, position and format of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n2.5.5.2 Map Style\nIn tmap, we can change a wide variety of layout settings using tmap_style(). The classic style is used here. Other available styles are: “white”, “gray”, “natural”, “cobalt”, “col_blind”, “albatross”, “beaver”, “bw”, “watercolor”\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\", \n          palette = \"-Greens\") + \n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n2.5.5.3 Cartographic Furniture\ntmap also provides arguments to draw other map furniture like compass, scale bar and grid lines.\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") + \n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2, \n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) + \n  tm_compass(type=\"8star\", size = 2) + \n  tm_scale_bar(width = 0.15) + \n  tm_grid(lwd = 0.1, alpha = 0.2) + \n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nTo reset to the default style, use the below code chunk.\n\ntmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n2.5.6 Drawing Small Multiple Choropleth Maps of Facet Maps\nSmall multiple maps or facet maps are composed of many maps arranged side-by-side or stacked vertically. Using facet maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n2.5.6.1 By assigning multiple values to at least one of the aesthetic arguments\nI created facet maps by defining col in tm_fill().\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(col = c(\"YOUNG\",\"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") + \n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) + \n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\nWe can also assign multiple values to aesthetic arguments like style and palette.\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n              style = c(\"equal\", \"quantile\"), \n              palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n2.5.6.2 By defining a group-by variable in tm_facets()\nWe can create facet maps using tm_facets().\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by = \"REGION_N\",\n            free.coords = TRUE,\n            drop.units  = TRUE) + #instead of drop.shapes as it is deprecated\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"),\n            title.size = 20) + \n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n2.5.6.3 By creating multiple stand-alone maps with tmap_arrange()\nWe can create facet maps by creating multiple stand-alone maps and arranging them. In tmap_arrange(), arguments ncol specifies the number of columns to have and asp refers to the aspect ratio of each map.\n\n#Create stand-alone maps\nyoungmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\n#Arrange Maps\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2) \n\n\n\n\nIf there are more than 2 maps, I can just add on for instance:\n\ntmap_arrange(youngmap, agedmap, youngmap, agedmap, asp=1.7, ncol=2)\n\n\n\n\n\n\n\n2.5.7 Mappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#references",
    "href": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#references",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "3 References",
    "text": "3 References\n\nR for Geospatial Data Science and Analytics - Chapter 1: Geospatial Data Wrangling with R\nR for Geospatial Data Science and Analytics - Chapter 2: Choropleth Mapping with R"
  },
  {
    "objectID": "Exercises/In-class_Ex1/In-class_Ex1.html",
    "href": "Exercises/In-class_Ex1/In-class_Ex1.html",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "In this in-class exercise, I learned how to compute spatial weights using R. Detailed objectives are as follows::\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute spatial weights using appropriate functions of spdep package, and\ncalculate spatially lagged variables using appropriate functions of spdep package."
  },
  {
    "objectID": "Exercises/In-class_Ex1/In-class_Ex1.html#study-area-and-data",
    "href": "Exercises/In-class_Ex1/In-class_Ex1.html#study-area-and-data",
    "title": "In-class Exercise 1",
    "section": "2 Study Area and Data",
    "text": "2 Study Area and Data\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012."
  },
  {
    "objectID": "Exercises/In-class_Ex1/In-class_Ex1.html#getting-started",
    "href": "Exercises/In-class_Ex1/In-class_Ex1.html#getting-started",
    "title": "In-class Exercise 1",
    "section": "3 Getting Started",
    "text": "3 Getting Started\nThe code chunk below will install and load sf, spdep, tmap and tidyverse packages.\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Exercises/In-class_Ex1/In-class_Ex1.html#import-data-into-r-environment",
    "href": "Exercises/In-class_Ex1/In-class_Ex1.html#import-data-into-r-environment",
    "title": "In-class Exercise 1",
    "section": "4 Import Data into R Environment",
    "text": "4 Import Data into R Environment\n\n4.1 Importing shape file into R\nThe code chunk below will import ESRI shape file into R.\n\nhunan <- st_read(dsn = \"data\\\\geospatial\",\n                layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\ameliachuayt\\ISSS624\\Exercises\\In-class_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nThe output shows that there are 88 multipolygon features and 7 fields.\n\n\n4.2 Import csv file into R\nThe code chunk below uses read_csv() of readr package to import Hunan_2012 csv file into R. The output R object is called hunan_2012 and is in R dataframe class.\n\nhunan2012<- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n4.3 Performing relational join\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\nhunan <- left_join(hunan, hunan2012)\n\nJoining, by = \"County\"\n\n\n\n\n4.4 Visualising Regional Development Indicator\nThe code chunk below is used to prepare two stand-alone maps: a basemap and a choropleth map showing the distribution of GDPPC 2012 by using gtm() of tmap package. Then by using tmap_arrange() of tmap package, we will create a facet map.\nNote that:\n\nGDPPC refers to Gross Domestic Product per capita.\nqtm() allows us to plot thematic maps quickly.\n\n\nbasemap <- tm_shape(hunan) + \n  tm_polygons() +\n  tm_text(\"NAME_3\", size = 0.5)\n\ngdppc <- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap,gdppc, asp = 1, ncol = 2)"
  },
  {
    "objectID": "hands-on.html",
    "href": "hands-on.html",
    "title": "Hands-on Exercises",
    "section": "",
    "text": "This is the section page where you may easily navigate to all the hands-on exercises that I have done."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS624",
    "section": "",
    "text": "In this webpage, I am going to share with you my learning journey of geospatial analytics."
  },
  {
    "objectID": "Exercises/In-class_Ex1/In-class_Ex1.html#computing-contiguity-spatial-weight",
    "href": "Exercises/In-class_Ex1/In-class_Ex1.html#computing-contiguity-spatial-weight",
    "title": "In-class Exercise 1",
    "section": "5 Computing Contiguity Spatial Weight",
    "text": "5 Computing Contiguity Spatial Weight\nIn this section, I learned how to use poly2nb() of spdep package to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. This function allows us to pass a “queen” argument that takes TRUE or FALSE as options. The default is set to TRUE, which means that the function will return a list of first order neighbours using the Queen criteria by default.\n\n5.1 Computing (Queen) contiguity based neighbours\nThe code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q <- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two least connected region with only one neighbour.\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object, type:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\nWe can use the code chunk below to retrieve county name of Polygon ID = 1. The output reveals that Polygon ID=1 is Anxiang county.\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nTo reveal the county names of Anxiang county’s five neighboring polygons, the code chunk will be used:\n\nhunan$County[c(2, 3,4, 57, 85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nAlternatively, we can combine the earlier steps to identify the five neighbours and get their names into one code chunk.\n\nhunan$County[wm_q[[1]]]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nNext, let’s retrieve the GDPPC of these five counties.\n\nnb1 <- wm_q[[1]]\ngdp1 <- hunan$GDPPC[nb1]\ngdp1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe printed output above shows that the GDPPC of the five nearest neighbours based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively.\n\n\n\n\n\n\nTip\n\n\n\nWe can combine them the names and GDPPC into a matrix by using cbind().\n\ncbind(hunan$County[wm_q[[1]]], gdp1)\n\n               gdp1   \n[1,] \"Hanshou\" \"20981\"\n[2,] \"Jinshi\"  \"34592\"\n[3,] \"Li\"      \"24473\"\n[4,] \"Nan\"     \"21311\"\n[5,] \"Taoyuan\" \"22879\"\n\n\n\n\nYou can display the complete weight matrix by using str().\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\n5.2 Creating (ROOK) contiguity based on neighbours\nThe code chunk below is used to compute Rook contiguity weight matrix.\n\nwm_r <- poly2nb(hunan, queen = FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connect area unit has 10 neighbours. There are two least connected regions with only one neighbours.\n\n\n5.3 Visualising contiguity weights\nA connectivity graph takes a point and displays a line to each neighboring point. Since we are working with polygons, we will need to get points in order to make our connectivity graphs. The most commonly used method to get points is to take the centroids of the polygons. We will calculate these in the sf package before moving onto the graphs.\n\n5.3.1 Getting Latitude and Longitude of Polygon Centroids\nWe need to associate each polygon with a point before we can make our connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object: hunan. I need the coordinates in a separate data frame for this to work. To do this I will use a mapping function.\nThe mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of hunan. Our function will be st_centroid(). We will be using map_dbl() variation of map from the purrr package. purrr is loaded when we load tidyverse.\nTo get our longitude values we map the st_centroid() function over the geometry column of hunan and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, I used cbind to put longitude and latitude into the same object. We should check the first few observations to see if things are formatted correctly.\n\ncoords <- cbind(longitude, latitude)\nhead(coords, 5)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n\n\n\n\n5.3.2 Plotting Queen contiguity based neighbours map\nWith the coordinates for each county, we can plot the neighbors through a connectivity graph.\nNotes on the arguments used in plot():\n\npch: plotting symbols available. ‘19’ refers to solid circles. Detailed list can be found here.\nadd: adds the current plot onto the previous plot\ncex: a numerical value giving the amount by which plotting text and symbols should be magnified relative to the default\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n5.3.3 Plotting Rook contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n5.3.4 Plotting both Queen and Rook contiguity based neighbours maps\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\", main=\"Queen Contiguity\")\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\", main=\"Rook Contiguity\")\n\n\n\n\nSince the queen criterion is somewhat more encompassing than rook criterion, the number of neighbors according to the queen criterion will always be at least as large as for the rook criterion. We can observe this in the above maps as well.\n\nRook criterion: defines neighbors by the existence of a common edge between two spatial units.\nQueen criterion: defines neighbors as spatial units sharing a common edge or a common vertex."
  },
  {
    "objectID": "Exercises/In-class_Ex1/In-class_Ex1.html#references",
    "href": "Exercises/In-class_Ex1/In-class_Ex1.html#references",
    "title": "In-class Exercise 1",
    "section": "9 References",
    "text": "9 References\n\nhttps://r4gdsa.netlify.app/chap03.html#spatial-lag-as-a-sum-of-neighboring-values\nhttps://spatialanalysis.github.io/handsonspatialdata/contiguity-based-spatial-weights.html"
  },
  {
    "objectID": "Exercises/In-class_Ex1/In-class_Ex1.html#computing-distance-based-neighbours",
    "href": "Exercises/In-class_Ex1/In-class_Ex1.html#computing-distance-based-neighbours",
    "title": "In-class Exercise 1",
    "section": "6 Computing distance based neighbours",
    "text": "6 Computing distance based neighbours\nIn this section, I learned how to derive distance-based weight matrices by using dnearneigh() of spdep package.\nThe function identifies neighbours of region points by Euclidean distance with a distance band with lower d1= and upper d2= bounds controlled by the bounds= argument. If unprojected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and longlat=TRUE, great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.\ndnearneigh(x, d1, d2, row.names = NULL, longlat = NULL, bounds=c(\"GE\", \"LE\"),\n use_kd_tree=TRUE, symtest=FALSE, use_s2=packageVersion(\"s2\") > \"1.0.7\", k=200,\n dwithin=TRUE)\n\n6.1 Determine the cut-off distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nknearneigh(x, k=1, longlat = NULL, use_kd_tree=TRUE)\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\nk1 <- knn2nb(knearneigh(coords, k=1)) #default k = 1\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\nhead(k1dists,5)\n\n[1] 25.53398 43.03114 25.53398 29.28480 29.28480\n\n\n\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n6.2 Computing fixed distance weight matrix\nNow, we will compute the distance weight matrix by using dnearneigh()as shown below.\n\nwm_d62 <- dnearneigh(coords,0,62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nFrom the output, we see that the average number of links is 3.68. This means that on average, the number of links each polygons has 3.68.\nNext, we will use str() to display the content of wm_d62 weight matrix.\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\nAnother way to display the structure of the weight matrix is to combine table() and card() of spdep.\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\nn.comp.nb() finds the number of disjoint connected subgraphs in the graph depicted by nb.obj - a spatial neighbours list object.\n\nn_comp <- n.comp.nb(wm_d62)\nn_comp\n\n$nc\n[1] 1\n\n$comp.id\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[39] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[77] 1 1 1 1 1 1 1 1 1 1 1 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\n6.2.1 Plotting fixed distance weight matrix\nNext, I will plot the distance weight matrix by using the code chunk below.\n\nplot(hunan$geometry, border = 'lightgrey') #base map\nplot(wm_d62, coords, add = TRUE) #neighbours within 62km\nplot(k1, coords, add = TRUE, col = 'red', length = 0.8) #1st nearest neigbours\n\n\n\n\n\npar(mfrow = c(1,2))\nplot(hunan$geometry, border = \"lightgrey\")\nplot(k1, coords, add = TRUE, col = \"red\", length = 0.88, main=\"1st nearest neighbours\")\n\nplot(hunan$geometry, border = \"lightgrey\")\nplot(wm_d62, coords, add = TRUE, pch = 19, cex = 0.6, main = \"Distance Link\")\n\n\n\n\n\n\n\n6.3 Computing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn6 <- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nSince we set k=6, the average number of links is also 6 since each county has 6 neighbours.\nSimilarly, we can display the content of the matrix by using str(). Notice that each county has exactly 6 neighbours.\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\n\n6.3.1 Plotting distance based neighbours\nWe can plot the weight matrix using the code chunk below.\n\nplot(hunan$geometry, color = 'lightgrey')\n\nWarning in title(...): \"color\" is not a graphical parameter\n\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = 'red')"
  },
  {
    "objectID": "Exercises/In-class_Ex1/In-class_Ex1.html#argum",
    "href": "Exercises/In-class_Ex1/In-class_Ex1.html#argum",
    "title": "In-class Exercise 1",
    "section": "7 Argum",
    "text": "7 Argum"
  },
  {
    "objectID": "Exercises/In-class_Ex1/In-class_Ex1.html#weights-based-on-idw",
    "href": "Exercises/In-class_Ex1/In-class_Ex1.html#weights-based-on-idw",
    "title": "In-class Exercise 1",
    "section": "7 Weights based on IDW",
    "text": "7 Weights based on IDW\nIn this section, I learned how to derive a spatial weight matrix based on Inversed Distance method.\nFirstly, let’s compute the distances between areas by using nbdists() of spdep.\n\ndist <- nbdists(wm_q, coords, longlat = TRUE)\nids <- lapply(dist, function(x) 1/(x)) #i.e. inverse distance = 1/distance\nhead(ids,10)\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n\n\n7.1 Row-standardised weights matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values.\nWhile this is the most intuitive way to summarise the neighbors’ values, it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data.\nFor this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\nThe zero.policy=TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy of FALSE would return an error.\n\nrswm_q <- nb2listw(wm_q, style = \"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nTo see the weight of the first polygon’s four neighbors type:\n\nrswm_q$weights[1]\n\n[[1]]\n[1] 0.2 0.2 0.2 0.2 0.2\n\n\nEach neighbor is assigned a 0.2 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.2 before being tallied.\nUsing the same method, we can also derive a row standardised distance weight matrix by using the code chunk below.\n\nrswm_ids <- nb2listw(wm_q, glist = ids, style = \"B\", zero.policy = TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "Exercises/In-class_Ex1/In-class_Ex1.html#application-of-spatial-weight-matrix",
    "href": "Exercises/In-class_Ex1/In-class_Ex1.html#application-of-spatial-weight-matrix",
    "title": "In-class Exercise 1",
    "section": "8 Application of Spatial Weight Matrix",
    "text": "8 Application of Spatial Weight Matrix\nIn this section, I learned how to create four different spatial lagged variables, they are:\n\nspatial lag with row-standardized weights,\nspatial lag as a sum of neighbouring values,\nspatial window average and\nspatial window sum.\n\n\n8.1 Spatial lag with row-standardised weights\nFinally, we’ll compute the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values.\n\nGDPPC.lag <- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nRecall that in the previous section, we retrieved the GDPPC of these five counties by using the code chunk below\n\nnb1 <- wm_q[[1]]\nnb1 <- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: Can you see the meaning of Spatial lag with row-standardized weights now?\n\nmean(nb1)\n\n[1] 24847.2\n\n\nTaking the mean of the GDPPC of the five neighbours of county 1 will return the same value as the first value of GDPPC.lag.\n\n\nWe can append the spatially lag GDPPC values onto hunan sf data frame by using the code chunk below.\n\nlag.list <- list(hunan$County, lag.listw(rswm_q, hunan$GDPPC))\nlag.res <- as.data.frame(lag.list)\ncolnames(lag.res) <- c(\"County\", \"lag GDPPC\")\nhead(lag.res)\n\n   County lag GDPPC\n1 Anxiang  24847.20\n2 Hanshou  22724.80\n3  Jinshi  24143.25\n4      Li  27737.50\n5   Linli  27270.25\n6  Shimen  21248.80\n\n\n\nhunan <- left_join(hunan, lag.res)\n\nJoining, by = \"County\"\n\n\nThe following table shows the average neighboring income values (stored in the Inc.lag object) for each county.\n\nhead(hunan)\n\nSimple feature collection with 6 features and 36 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3 Shape_Leng Shape_Area  County    City\n1 Changde 21098 Anxiang      County   1.869074 0.10056190 Anxiang Changde\n2 Changde 21100 Hanshou      County   2.360691 0.19978745 Hanshou Changde\n3 Changde 21101  Jinshi County City   1.425620 0.05302413  Jinshi Changde\n4 Changde 21102      Li      County   3.474325 0.18908121      Li Changde\n5 Changde 21103   Linli      County   2.289506 0.11450357   Linli Changde\n6 Changde 21104  Shimen      County   4.171918 0.37194707  Shimen Changde\n  avg_wage deposite     FAI Gov_Rev Gov_Exp     GDP GDPPC     GIO   Loan  NIPCR\n1    31935   5517.2  3541.0  243.64  1779.5 12482.0 23667  5108.9 2806.9 7693.7\n2    32265   7979.0  8665.0  386.13  2062.4 15788.0 20981 13491.0 4550.0 8269.9\n3    28692   4581.7  4777.0  373.31  1148.4  8706.9 34592 10935.0 2242.0 8169.9\n4    32541  13487.0 16066.0  709.61  2459.5 20322.0 24473 18402.0 6748.0 8377.0\n5    32667    564.1  7781.2  336.86  1538.7 10355.0 25554  8214.0  358.0 8143.1\n6    33261   8334.4 10531.0  548.33  2178.8 16293.0 27137 17795.0 6026.5 6156.0\n   Bed    Emp  EmpR EmpRT Pri_Stu Sec_Stu Household Household_R NOIP Pop_R\n1 1931 336.39 270.5 205.9  19.584  17.819     148.1       135.4   53 346.0\n2 2560 456.78 388.8 246.7  42.097  33.029     240.2       208.7   95 553.2\n3  848 122.78  82.1  61.7   8.723   7.592      81.9        43.7   77  92.4\n4 2038 513.44 426.8 227.1  38.975  33.938     268.5       256.0   96 539.7\n5 1440 307.36 272.2 100.8  23.286  18.943     129.1       157.2   99 246.6\n6 2502 392.05 329.6 193.8  29.245  26.104     190.6       184.7  122 399.2\n    RSCG Pop_T    Agri Service Disp_Inc      RORP    ROREmp lag GDPPC\n1 3957.9 528.3 4524.41   14100    16610 0.6549309 0.8041262  24847.20\n2 4460.5 804.6 6545.35   17727    18925 0.6875466 0.8511756  22724.80\n3 3683.0 251.8 2562.46    7525    19498 0.3669579 0.6686757  24143.25\n4 7110.2 832.5 7562.34   53160    18985 0.6482883 0.8312558  27737.50\n5 3604.9 409.3 3583.91    7031    18604 0.6024921 0.8856065  27270.25\n6 6490.7 600.5 5266.51    6981    19275 0.6647794 0.8407091  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below.\n\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_gdppc <- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp = 1, ncol =2)\n\n\n\n\n\n\n8.2 Spatial lag as a sum of neighbouring values\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw() to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply(), which applies a function across each value in the neighbors structure.\n\nb_weights <- lapply(wm_q, function(x) 0*x + 1)\nhead(b_weights)\n\n[[1]]\n[1] 1 1 1 1 1\n\n[[2]]\n[1] 1 1 1 1 1\n\n[[3]]\n[1] 1 1 1 1\n\n[[4]]\n[1] 1 1 1 1\n\n[[5]]\n[1] 1 1 1 1\n\n[[6]]\n[1] 1 1 1 1 1\n\nb_weights2 <- nb2listw(wm_q,\n                       glist = b_weights,\n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw() to compute a lag variable from our weight and GDPPC.\n\nlag_sum <- list(hunan$County, lag.listw(b_weights2, hunan$GDPPC))\nlag.res <- as.data.frame(lag_sum)\ncolnames(lag.res) <- c(\"County\", \"lag_sum GDPPC\")\nhead(lag.res)\n\n   County lag_sum GDPPC\n1 Anxiang        124236\n2 Hanshou        113624\n3  Jinshi         96573\n4      Li        110950\n5   Linli        109081\n6  Shimen        106244\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: Can you understand the meaning of Spatial lag as a sum of neighbouring values now?\nLike the term suggests, the spatial lag is now the sum of neighbouring values. We can verify by taking the sum of county 1’s neighbours’ GDPPC.\n\nsum(nb1)\n\n[1] 124236\n\n\n\n\nNext, we will append the lag_sum GDPPC field into hunan sf data frame by using the code chunk below.\n\nhunan <- left_join(hunan, lag.res)\n\nJoining, by = \"County\"\n\n\nNow, we can plot both GDPPC and Spatial Lag Sum GDPPC for comparison.\n\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc <- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp = 1, ncol = 2)\n\n\n\n\n\n\n8.3 Spatial Window Average\nThe spatial window average uses row-standardises weights and includes the diagonal element. To do this in R, we need to go back to the neighbours structure and add the diagonal element before assignment weights. To begin, we assign wm_q to a new variable because we will directly alter its structure to add the diagonal elements.\n\nwm_q1 <- wm_q\n\nTo add the diagonal element to the neighbour list, we can use include.self() from spdep.\n\ninclude.self(wm_q1)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNow obtain weights with nb2listw().\n\nwm_q1 <- nb2listw(wm_q1)\nwm_q1\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nWe can create the lag variable from our weight structure and GDPPC variable.\n\nlag_w_avg_gdppc <- lag.listw(wm_q1,\n                             hunan$GDPPC)\n\nlag.list.wm_q1 <- list(hunan$County, lag_w_avg_gdppc)\nlag_wm_q1.res <- as.data.frame(lag.list.wm_q1)\ncolnames(lag_wm_q1.res) <- c(\"County\", \"lag_window_avg GDPPC\")\n\nLet’s append the lag_window_avg GDPPC values onto hunan sf data.frame.\n\nhunan <- left_join(hunan, lag_wm_q1.res)\n\nJoining, by = \"County\"\n\n\nFinally, let’s compare the GDPPC and lag_window_avg GDPPC.\n\ngdppc <- qtm(hunan, \"GDPPC\")\nw_avg_gdppc <- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(gdppc, w_avg_gdppc, asp = 1, ncol = 2)\n\n\n\n\n\n\n8.4 Spatial Window Sum\nThe spatial window sum is the country part of window average, but without using row-standardised weights. To do this, we assign binary weights to the neighbour structure that includes the diagonal element.\n\nwm_q1 <- wm_q\n\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\ninclude.self(wm_q1)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\n\nwm_q1\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\n\nNext, we will assign binary weights to the neighbour structure that includes the diagonal element.\n\nb_weights <- lapply(wm_q1, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1\n\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights2 <- nb2listw(wm_q1,\n                       glist = b_weights,\n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith our new weight structure, we can compute the lag variable with lag.listw().\n\nw_sum_gdppc <- list(hunan$County, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc.res <- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) <- c(\"County\", \"w_sum GDPPC\")\n\nNext, the code chunk below will be used to append w_sum GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan <- left_join(hunan, w_sum_gdppc.res)\n\nJoining, by = \"County\"\n\n\nLastly, qtm() of tmap package is used to plot the GDPPC and lag_sum GDPPC map next to each other for quick comparison.\n\ngdppc <- qtm(hunan, \"GDPPC\")\nw_sum_gdppc <- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(gdppc, w_sum_gdppc, asp = 1, ncol = 2)"
  },
  {
    "objectID": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#overview-of-geospatial-data-wrangling",
    "href": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#overview-of-geospatial-data-wrangling",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "1.1 Overview of Geospatial Data Wrangling",
    "text": "1.1 Overview of Geospatial Data Wrangling\nIn the first of this two-part hands-on exercise, I learned how to import, and wrangle geospatial data using appropriate R packages."
  },
  {
    "objectID": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#overview-of-choropleth-mapping-with-r",
    "href": "Exercises/Hands-on_Ex1/Hands-on_Ex1.html#overview-of-choropleth-mapping-with-r",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling and Choropleth Mapping with R",
    "section": "2.1 Overview of Choropleth Mapping with R",
    "text": "2.1 Overview of Choropleth Mapping with R\nIn the second of this two-part hands-on exercise, I learned how to plot functional and truthful choropleth maps by using an R package called tmap package.\nChoropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary."
  }
]